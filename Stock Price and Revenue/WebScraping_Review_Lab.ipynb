{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd15015e-1060-4937-a29b-2364e6bda561",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network\" target=\"_blank\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\">\n",
    "    </a>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e36dc6-ec90-4bd0-8971-a0ff68a495f4",
   "metadata": {},
   "source": [
    "# **Web Scraping Lab**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17780836-64c7-46bf-a577-538fd544f03d",
   "metadata": {},
   "source": [
    "Estimated time needed: **30** minutes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d55e62b-8cc8-410c-92fb-19a1ae129b49",
   "metadata": {},
   "source": [
    "## Objectives\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c03997d-bb95-44b2-8964-96ca0a7e7998",
   "metadata": {},
   "source": [
    "After completing this lab you will be able to:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c568bb-89d6-462a-81b9-c4bd6f255dd9",
   "metadata": {},
   "source": [
    "<h2>Table of Contents</h2>\n",
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
    "    <ul>\n",
    "        <li>\n",
    "            <a href=\"https://bso/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkPY0220ENSkillsNetwork23455606-2021-01-01\">Beautiful Soup Object</a>\n",
    "            <ul>\n",
    "                <li>Tag</li>\n",
    "                <li>Children, Parents, and Siblings</li>\n",
    "                <li>HTML Attributes</li>\n",
    "                <li>Navigable String</li>\n",
    "            </ul>\n",
    "        </li>\n",
    "     </ul>\n",
    "    <ul>\n",
    "        <li>\n",
    "            <a href=\"https://filter/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkPY0220ENSkillsNetwork23455606-2021-01-01\">Filter</a>\n",
    "            <ul>\n",
    "                <li>find All</li>\n",
    "                <li>find </li>\n",
    "                <li>HTML Attributes</li>\n",
    "                <li>Navigable String</li>\n",
    "            </ul>\n",
    "        </li>\n",
    "     </ul>\n",
    "     <ul>\n",
    "        <li>\n",
    "            <a href=\"https://dscw/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkPY0220ENSkillsNetwork23455606-2021-01-01\">Downloading And Scraping The Contents Of A Web</a>\n",
    "    </li>\n",
    "         </ul>\n",
    "    <p>\n",
    "        Estimated time needed: <strong>25 min</strong>\n",
    "    </p>\n",
    "\n",
    "</div>\n",
    "\n",
    "<hr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2a3092-8f35-4498-bcca-3662c546c2b8",
   "metadata": {},
   "source": [
    "For this lab, we are going to be using Python and several Python libraries. Some of these libraries might be installed in your lab environment or in SN Labs. Others may need to be installed by you. The cells below will install these libraries when executed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a64fc33-fc56-45df-8be6-c308d1ecfdea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Usage:   \n",
      "  d:\\Data Science Project\\.venv\\Scripts\\python.exe -m pip install [options] <requirement specifier> [package-index-options] ...\n",
      "  d:\\Data Science Project\\.venv\\Scripts\\python.exe -m pip install [options] -r <requirements file> [package-index-options] ...\n",
      "  d:\\Data Science Project\\.venv\\Scripts\\python.exe -m pip install [options] [-e] <vcs project url> ...\n",
      "  d:\\Data Science Project\\.venv\\Scripts\\python.exe -m pip install [options] [-e] <local project path> ...\n",
      "  d:\\Data Science Project\\.venv\\Scripts\\python.exe -m pip install [options] <archive url/path> ...\n",
      "\n",
      "no such option: -y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lxml==4.6.4\n",
      "  Using cached lxml-4.6.4.tar.gz (3.2 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Building wheels for collected packages: lxml\n",
      "  Building wheel for lxml (pyproject.toml): started\n",
      "  Building wheel for lxml (pyproject.toml): finished with status 'error'\n",
      "Failed to build lxml\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × Building wheel for lxml (pyproject.toml) did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [85 lines of output]\n",
      "      Building lxml version 4.6.4.\n",
      "      <string>:67: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "      Building without Cython.\n",
      "      Building against pre-built libxml2 andl libxslt libraries\n",
      "      C:\\Users\\epics\\AppData\\Local\\Temp\\pip-build-env-_q5w0prf\\overlay\\Lib\\site-packages\\setuptools\\dist.py:759: SetuptoolsDeprecationWarning: License classifiers are deprecated.\n",
      "      !!\n",
      "      \n",
      "              ********************************************************************************\n",
      "              Please consider removing the following classifiers in favor of a SPDX license expression:\n",
      "      \n",
      "              License :: OSI Approved :: BSD License\n",
      "      \n",
      "              See https://packaging.python.org/en/latest/guides/writing-pyproject-toml/#license for details.\n",
      "              ********************************************************************************\n",
      "      \n",
      "      !!\n",
      "        self._finalize_license_expression()\n",
      "      running bdist_wheel\n",
      "      running build\n",
      "      running build_py\n",
      "      creating build\\lib.win-amd64-cpython-314\\lxml\n",
      "      copying src\\lxml\\builder.py -> build\\lib.win-amd64-cpython-314\\lxml\n",
      "      copying src\\lxml\\cssselect.py -> build\\lib.win-amd64-cpython-314\\lxml\n",
      "      copying src\\lxml\\doctestcompare.py -> build\\lib.win-amd64-cpython-314\\lxml\n",
      "      copying src\\lxml\\ElementInclude.py -> build\\lib.win-amd64-cpython-314\\lxml\n",
      "      copying src\\lxml\\pyclasslookup.py -> build\\lib.win-amd64-cpython-314\\lxml\n",
      "      copying src\\lxml\\sax.py -> build\\lib.win-amd64-cpython-314\\lxml\n",
      "      copying src\\lxml\\usedoctest.py -> build\\lib.win-amd64-cpython-314\\lxml\n",
      "      copying src\\lxml\\_elementpath.py -> build\\lib.win-amd64-cpython-314\\lxml\n",
      "      copying src\\lxml\\__init__.py -> build\\lib.win-amd64-cpython-314\\lxml\n",
      "      creating build\\lib.win-amd64-cpython-314\\lxml\\includes\n",
      "      copying src\\lxml\\includes\\__init__.py -> build\\lib.win-amd64-cpython-314\\lxml\\includes\n",
      "      creating build\\lib.win-amd64-cpython-314\\lxml\\html\n",
      "      copying src\\lxml\\html\\builder.py -> build\\lib.win-amd64-cpython-314\\lxml\\html\n",
      "      copying src\\lxml\\html\\clean.py -> build\\lib.win-amd64-cpython-314\\lxml\\html\n",
      "      copying src\\lxml\\html\\defs.py -> build\\lib.win-amd64-cpython-314\\lxml\\html\n",
      "      copying src\\lxml\\html\\diff.py -> build\\lib.win-amd64-cpython-314\\lxml\\html\n",
      "      copying src\\lxml\\html\\ElementSoup.py -> build\\lib.win-amd64-cpython-314\\lxml\\html\n",
      "      copying src\\lxml\\html\\formfill.py -> build\\lib.win-amd64-cpython-314\\lxml\\html\n",
      "      copying src\\lxml\\html\\html5parser.py -> build\\lib.win-amd64-cpython-314\\lxml\\html\n",
      "      copying src\\lxml\\html\\soupparser.py -> build\\lib.win-amd64-cpython-314\\lxml\\html\n",
      "      copying src\\lxml\\html\\usedoctest.py -> build\\lib.win-amd64-cpython-314\\lxml\\html\n",
      "      copying src\\lxml\\html\\_diffcommand.py -> build\\lib.win-amd64-cpython-314\\lxml\\html\n",
      "      copying src\\lxml\\html\\_html5builder.py -> build\\lib.win-amd64-cpython-314\\lxml\\html\n",
      "      copying src\\lxml\\html\\_setmixin.py -> build\\lib.win-amd64-cpython-314\\lxml\\html\n",
      "      copying src\\lxml\\html\\__init__.py -> build\\lib.win-amd64-cpython-314\\lxml\\html\n",
      "      creating build\\lib.win-amd64-cpython-314\\lxml\\isoschematron\n",
      "      copying src\\lxml\\isoschematron\\__init__.py -> build\\lib.win-amd64-cpython-314\\lxml\\isoschematron\n",
      "      copying src\\lxml\\etree.h -> build\\lib.win-amd64-cpython-314\\lxml\n",
      "      copying src\\lxml\\etree_api.h -> build\\lib.win-amd64-cpython-314\\lxml\n",
      "      copying src\\lxml\\lxml.etree.h -> build\\lib.win-amd64-cpython-314\\lxml\n",
      "      copying src\\lxml\\lxml.etree_api.h -> build\\lib.win-amd64-cpython-314\\lxml\n",
      "      copying src\\lxml\\includes\\c14n.pxd -> build\\lib.win-amd64-cpython-314\\lxml\\includes\n",
      "      copying src\\lxml\\includes\\config.pxd -> build\\lib.win-amd64-cpython-314\\lxml\\includes\n",
      "      copying src\\lxml\\includes\\dtdvalid.pxd -> build\\lib.win-amd64-cpython-314\\lxml\\includes\n",
      "      copying src\\lxml\\includes\\etreepublic.pxd -> build\\lib.win-amd64-cpython-314\\lxml\\includes\n",
      "      copying src\\lxml\\includes\\htmlparser.pxd -> build\\lib.win-amd64-cpython-314\\lxml\\includes\n",
      "      copying src\\lxml\\includes\\relaxng.pxd -> build\\lib.win-amd64-cpython-314\\lxml\\includes\n",
      "      copying src\\lxml\\includes\\schematron.pxd -> build\\lib.win-amd64-cpython-314\\lxml\\includes\n",
      "      copying src\\lxml\\includes\\tree.pxd -> build\\lib.win-amd64-cpython-314\\lxml\\includes\n",
      "      copying src\\lxml\\includes\\uri.pxd -> build\\lib.win-amd64-cpython-314\\lxml\\includes\n",
      "      copying src\\lxml\\includes\\xinclude.pxd -> build\\lib.win-amd64-cpython-314\\lxml\\includes\n",
      "      copying src\\lxml\\includes\\xmlerror.pxd -> build\\lib.win-amd64-cpython-314\\lxml\\includes\n",
      "      copying src\\lxml\\includes\\xmlparser.pxd -> build\\lib.win-amd64-cpython-314\\lxml\\includes\n",
      "      copying src\\lxml\\includes\\xmlschema.pxd -> build\\lib.win-amd64-cpython-314\\lxml\\includes\n",
      "      copying src\\lxml\\includes\\xpath.pxd -> build\\lib.win-amd64-cpython-314\\lxml\\includes\n",
      "      copying src\\lxml\\includes\\xslt.pxd -> build\\lib.win-amd64-cpython-314\\lxml\\includes\n",
      "      copying src\\lxml\\includes\\__init__.pxd -> build\\lib.win-amd64-cpython-314\\lxml\\includes\n",
      "      copying src\\lxml\\includes\\etree_defs.h -> build\\lib.win-amd64-cpython-314\\lxml\\includes\n",
      "      copying src\\lxml\\includes\\lxml-version.h -> build\\lib.win-amd64-cpython-314\\lxml\\includes\n",
      "      creating build\\lib.win-amd64-cpython-314\\lxml\\isoschematron\\resources\\rng\n",
      "      copying src\\lxml\\isoschematron\\resources\\rng\\iso-schematron.rng -> build\\lib.win-amd64-cpython-314\\lxml\\isoschematron\\resources\\rng\n",
      "      creating build\\lib.win-amd64-cpython-314\\lxml\\isoschematron\\resources\\xsl\n",
      "      copying src\\lxml\\isoschematron\\resources\\xsl\\RNG2Schtrn.xsl -> build\\lib.win-amd64-cpython-314\\lxml\\isoschematron\\resources\\xsl\n",
      "      copying src\\lxml\\isoschematron\\resources\\xsl\\XSD2Schtrn.xsl -> build\\lib.win-amd64-cpython-314\\lxml\\isoschematron\\resources\\xsl\n",
      "      creating build\\lib.win-amd64-cpython-314\\lxml\\isoschematron\\resources\\xsl\\iso-schematron-xslt1\n",
      "      copying src\\lxml\\isoschematron\\resources\\xsl\\iso-schematron-xslt1\\iso_abstract_expand.xsl -> build\\lib.win-amd64-cpython-314\\lxml\\isoschematron\\resources\\xsl\\iso-schematron-xslt1\n",
      "      copying src\\lxml\\isoschematron\\resources\\xsl\\iso-schematron-xslt1\\iso_dsdl_include.xsl -> build\\lib.win-amd64-cpython-314\\lxml\\isoschematron\\resources\\xsl\\iso-schematron-xslt1\n",
      "      copying src\\lxml\\isoschematron\\resources\\xsl\\iso-schematron-xslt1\\iso_schematron_message.xsl -> build\\lib.win-amd64-cpython-314\\lxml\\isoschematron\\resources\\xsl\\iso-schematron-xslt1\n",
      "      copying src\\lxml\\isoschematron\\resources\\xsl\\iso-schematron-xslt1\\iso_schematron_skeleton_for_xslt1.xsl -> build\\lib.win-amd64-cpython-314\\lxml\\isoschematron\\resources\\xsl\\iso-schematron-xslt1\n",
      "      copying src\\lxml\\isoschematron\\resources\\xsl\\iso-schematron-xslt1\\iso_svrl_for_xslt1.xsl -> build\\lib.win-amd64-cpython-314\\lxml\\isoschematron\\resources\\xsl\\iso-schematron-xslt1\n",
      "      copying src\\lxml\\isoschematron\\resources\\xsl\\iso-schematron-xslt1\\readme.txt -> build\\lib.win-amd64-cpython-314\\lxml\\isoschematron\\resources\\xsl\\iso-schematron-xslt1\n",
      "      running build_ext\n",
      "      building 'lxml.etree' extension\n",
      "      error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for lxml\n",
      "error: failed-wheel-build-for-install\n",
      "\n",
      "× Failed to build installable wheels for some pyproject.toml based projects\n",
      "╰─> lxml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Usage:   \n",
      "  d:\\Data Science Project\\.venv\\Scripts\\python.exe -m pip install [options] <requirement specifier> [package-index-options] ...\n",
      "  d:\\Data Science Project\\.venv\\Scripts\\python.exe -m pip install [options] -r <requirements file> [package-index-options] ...\n",
      "  d:\\Data Science Project\\.venv\\Scripts\\python.exe -m pip install [options] [-e] <vcs project url> ...\n",
      "  d:\\Data Science Project\\.venv\\Scripts\\python.exe -m pip install [options] [-e] <local project path> ...\n",
      "  d:\\Data Science Project\\.venv\\Scripts\\python.exe -m pip install [options] <archive url/path> ...\n",
      "\n",
      "no such option: -y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests==2.26.0 in d:\\data science project\\.venv\\lib\\site-packages (2.26.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\data science project\\.venv\\lib\\site-packages (from requests==2.26.0) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\data science project\\.venv\\lib\\site-packages (from requests==2.26.0) (2025.11.12)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in d:\\data science project\\.venv\\lib\\site-packages (from requests==2.26.0) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\data science project\\.venv\\lib\\site-packages (from requests==2.26.0) (3.11)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install bs4==4.10.0 -y\n",
    "%pip install lxml==4.6.4\n",
    "%pip install html5lib==1.1 -y\n",
    "%pip install requests==2.26.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6085fd-ba64-4559-8d44-e9d3e9321712",
   "metadata": {},
   "source": [
    "Import the required modules and functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in d:\\data science project\\.venv\\lib\\site-packages (4.14.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in d:\\data science project\\.venv\\lib\\site-packages (from beautifulsoup4) (2.8)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in d:\\data science project\\.venv\\lib\\site-packages (from beautifulsoup4) (4.15.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade beautifulsoup4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in d:\\data science project\\.venv\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in d:\\data science project\\.venv\\lib\\site-packages (from pandas) (2.3.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\data science project\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\data science project\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\data science project\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in d:\\data science project\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da3a316c-2600-4c2f-9961-61333aa25929",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup # this module helps in web scrapping.\n",
    "import requests  # this module helps us to download a web page"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705ba0ec-1664-49a0-a0f3-8e30dae75a80",
   "metadata": {},
   "source": [
    "<h2 id=\"BSO\">Beautiful Soup Objects</h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb85a9e-89d3-4a34-aa63-d0f355ce023d",
   "metadata": {},
   "source": [
    "Beautiful Soup is a Python library for pulling data out of HTML and XML files, we will focus on HTML files. This is accomplished by representing the HTML as a set of objects with methods used to parse the HTML.  We can navigate the HTML as a tree and/or filter out what we are looking for.\n",
    "\n",
    "Consider the following HTML:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72aa271e-9be5-47a4-bf76-604b47623a4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<!DOCTYPE html>\n",
       "<html>\n",
       "<head>\n",
       "<title>Page Title</title>\n",
       "</head>\n",
       "<body>\n",
       "<h3><b id='boldest'>Lebron James</b></h3>\n",
       "<p> Salary: $ 92,000,000 </p>\n",
       "<h3> Stephen Curry</h3>\n",
       "<p> Salary: $85,000, 000 </p>\n",
       "<h3> Kevin Durant </h3>\n",
       "<p> Salary: $73,200, 000</p>\n",
       "</body>\n",
       "</html>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "<title>Page Title</title>\n",
    "</head>\n",
    "<body>\n",
    "<h3><b id='boldest'>Lebron James</b></h3>\n",
    "<p> Salary: $ 92,000,000 </p>\n",
    "<h3> Stephen Curry</h3>\n",
    "<p> Salary: $85,000, 000 </p>\n",
    "<h3> Kevin Durant </h3>\n",
    "<p> Salary: $73,200, 000</p>\n",
    "</body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b95db9-b629-41a5-ab8f-0767708a54e3",
   "metadata": {},
   "source": [
    "We can store it as a string in the variable HTML:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "330dfe2d-7856-4758-9a94-466927fb432c",
   "metadata": {},
   "outputs": [],
   "source": [
    "html=\"<!DOCTYPE html><html><head><title>Page Title</title></head><body><h3><b id='boldest'>Lebron James</b></h3><p> Salary: $ 92,000,000 </p><h3> Stephen Curry</h3><p> Salary: $85,000, 000 </p><h3> Kevin Durant </h3><p> Salary: $73,200, 000</p></body></html>\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66344deb-d77a-4227-a2d1-ce4bfcff6956",
   "metadata": {},
   "source": [
    "To parse a document, pass it into the <code>BeautifulSoup</code> constructor, the <code>BeautifulSoup</code> object, which represents the document as a nested data structure:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26d5b278-d95c-4a4f-82a7-6521c2a36d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(html, \"html.parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc30a93-653e-4ac3-a495-52efc749bb8c",
   "metadata": {},
   "source": [
    "First, the document is converted to Unicode, (similar to ASCII),  and HTML entities are converted to Unicode characters. Beautiful Soup transforms a complex HTML document into a complex tree of Python objects. The <code>BeautifulSoup</code> object can create other types of objects. In this lab, we will cover <code>BeautifulSoup</code> and <code>Tag</code> objects that for the purposes of this lab are identical, and <code>NavigableString</code> objects.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01df0ea4-b24e-4433-94f3-46bd9171fca1",
   "metadata": {},
   "source": [
    "We can use the method <code>prettify()</code> to display the HTML in the nested structure:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "adac257d-a609-444d-abe6-710d42ab1e31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html>\n",
      " <head>\n",
      "  <title>\n",
      "   Page Title\n",
      "  </title>\n",
      " </head>\n",
      " <body>\n",
      "  <h3>\n",
      "   <b id=\"boldest\">\n",
      "    Lebron James\n",
      "   </b>\n",
      "  </h3>\n",
      "  <p>\n",
      "   Salary: $ 92,000,000\n",
      "  </p>\n",
      "  <h3>\n",
      "   Stephen Curry\n",
      "  </h3>\n",
      "  <p>\n",
      "   Salary: $85,000, 000\n",
      "  </p>\n",
      "  <h3>\n",
      "   Kevin Durant\n",
      "  </h3>\n",
      "  <p>\n",
      "   Salary: $73,200, 000\n",
      "  </p>\n",
      " </body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08ffc83-0bea-4676-859d-81b3b390a313",
   "metadata": {},
   "source": [
    "## Tags\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e5aec2-b008-4be1-81ab-15475c981595",
   "metadata": {},
   "source": [
    "Let's say we want the  title of the page and the name of the top paid player we can use the <code>Tag</code>. The <code>Tag</code> object corresponds to an HTML tag in the original document, for example, the tag title.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96a5f7bd-a6f6-426d-9b11-6ee75dbf0fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tag object: <title>Page Title</title>\n"
     ]
    }
   ],
   "source": [
    "tag_object=soup.title\n",
    "print(\"tag object:\",tag_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4f041b-c335-4e7e-92d4-3360c5aaba0c",
   "metadata": {},
   "source": [
    "we can see the tag type <code>bs4.element.Tag</code>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "20eb0275-e0b8-4e15-8df0-3add3c53a95f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tag object type: <class 'bs4.element.Tag'>\n"
     ]
    }
   ],
   "source": [
    "print(\"tag object type:\",type(tag_object))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e1f1d9-1192-40a2-91c3-e40b9eed706a",
   "metadata": {},
   "source": [
    "If there is more than one <code>Tag</code>  with the same name, the first element with that <code>Tag</code> name is called, this corresponds to the most paid player:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e57f737-34dc-4857-9942-d72d6469adcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<h3><b id=\"boldest\">Lebron James</b></h3>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_object=soup.h3\n",
    "tag_object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ead97a9-fcea-4374-90ae-6c8da7ba5718",
   "metadata": {},
   "source": [
    "Enclosed in the bold attribute <code>b</code>, it helps to use the tree representation. We can navigate down the tree using the child attribute to get the name.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6467af6-9548-45fd-97c7-647040a35a60",
   "metadata": {},
   "source": [
    "### Children, Parents, and Siblings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef12afd-ce6a-464b-9247-554cdec56fa6",
   "metadata": {},
   "source": [
    "As stated above the <code>Tag</code> object is a tree of objects we can access the child of the tag or navigate down the branch as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c808b908-b4d9-4655-b8be-b76c154fe5e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<b id=\"boldest\">Lebron James</b>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_child =tag_object.b\n",
    "tag_child"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cad7de-8d31-43a0-8598-7a39bf26851c",
   "metadata": {},
   "source": [
    "You can access the parent with the <code> parent</code>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bbd1296e-718e-41a4-a891-963dcd8384d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<h3><b id=\"boldest\">Lebron James</b></h3>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parent_tag=tag_child.parent\n",
    "parent_tag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b550c284-f6bb-4c3a-b0a6-f5dc5311fcf7",
   "metadata": {},
   "source": [
    "this is identical to\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6ba65bb0-2153-4aa6-83f0-9d82d4079085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<h3><b id=\"boldest\">Lebron James</b></h3>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8968d045-1dad-4cd8-83d2-68be65d72a07",
   "metadata": {},
   "source": [
    "<code>tag_object</code> parent is the <code>body</code> element.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d5be56b2-5078-4f85-aeeb-81499f5a2b92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<body><h3><b id=\"boldest\">Lebron James</b></h3><p> Salary: $ 92,000,000 </p><h3> Stephen Curry</h3><p> Salary: $85,000, 000 </p><h3> Kevin Durant </h3><p> Salary: $73,200, 000</p></body>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_object.parent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47282098-feb7-4393-a8d2-b64f92e5b8a6",
   "metadata": {},
   "source": [
    "<code>tag_object</code> sibling is the <code>paragraph</code> element\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "64c61033-97aa-4a6f-aedf-c1640a7efa3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p> Salary: $ 92,000,000 </p>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sibling_1=tag_object.next_sibling\n",
    "sibling_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cef62a4-64cd-42ef-9e24-cec164691504",
   "metadata": {},
   "source": [
    "`sibling_2` is the `header` element which is also a sibling of both `sibling_1` and `tag_object`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "df3a912f-ccc8-4368-8f7f-3b228a756674",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<h3> Stephen Curry</h3>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sibling_2=sibling_1.next_sibling\n",
    "sibling_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd63056-b86f-40b2-a6bb-071df7127ab3",
   "metadata": {},
   "source": [
    "<h3 id=\"first_question\">Exercise: <code>next_sibling</code></h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328472fa-44bf-40a7-a265-e5f1efb87efa",
   "metadata": {},
   "source": [
    "Using the object <code>sibling\\_2</code> and the property <code>next_sibling</code> to find the salary of Stephen Curry:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fe5656f9-fbdc-4019-b109-73c52a82cb27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<h3> Stephen Curry</h3>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sibling_2.next_sibling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fac4fb-fc36-45ab-9922-f7aacedaeb7d",
   "metadata": {},
   "source": [
    "<details><summary>Click here for the solution</summary>\n",
    "\n",
    "```\n",
    "sibling_2.next_sibling\n",
    "\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c1127e-2871-44b2-8e98-ce2ae1709cad",
   "metadata": {},
   "source": [
    "### HTML Attributes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e641ba29-b8a6-41a7-9ce6-705c2dd3b3e5",
   "metadata": {},
   "source": [
    "If the tag has attributes, the tag <code>id=\"boldest\"</code> has an attribute <code>id</code> whose value is <code>boldest</code>. You can access a tag’s attributes by treating the tag like a dictionary:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4b6d720c-a2d5-472c-bb5c-6f8195e3d2d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'boldest'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_child['id']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9c524e-be41-423e-95a3-7b3c49903060",
   "metadata": {},
   "source": [
    "You can access that dictionary directly as <code>attrs</code>:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7897c11e-4de4-436c-9b44-19bb5d8fc277",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'boldest'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_child.attrs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ed91c9-0004-420f-83a8-6013151618d9",
   "metadata": {},
   "source": [
    "You can also work with Multi-valued attribute check out <a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkPY0220ENSkillsNetwork23455606-2021-01-01\">\\[1]</a> for more.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075da70a-6cbc-4c4e-85c7-c40e6ab3add8",
   "metadata": {},
   "source": [
    "We can also obtain the content if the attribute of the <code>tag</code> using the Python <code>get()</code> method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6ce8df16-6bc8-4ff8-bdeb-5369ab06eb72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'boldest'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_child.get('id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae4e25e-5283-4952-b3d0-81d696c93391",
   "metadata": {},
   "source": [
    "### Navigable String\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06de462f-36d5-4f2b-bb5a-177ce7289a99",
   "metadata": {},
   "source": [
    "A string corresponds to a bit of text or content within a tag. Beautiful Soup uses the <code>NavigableString</code> class to contain this text. In our HTML we can obtain the name of the first player by extracting the string of the <code>Tag</code> object <code>tag_child</code> as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "54789f81-e8a4-419a-9732-bc89e94303b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Lebron James'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_string=tag_child.string\n",
    "tag_string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7bdba8-8f7b-4105-8a1d-e58a780edada",
   "metadata": {},
   "source": [
    "we can verify the type is Navigable String\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8be7f296-312b-49d2-8026-14a313974679",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.element.NavigableString"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tag_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7067801-0ab1-45e3-808e-ba60df82b3be",
   "metadata": {},
   "source": [
    "A NavigableString is just like a Python string or Unicode string, to be more precise. The main difference is that it also supports some  <code>BeautifulSoup</code> features. We can covert it to sting object in Python:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cfb79855-5bd4-4d8f-bb32-757a110999e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Lebron James'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unicode_string = str(tag_string)\n",
    "unicode_string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16f36d3-d541-4889-8f47-37d8f5c6dfcf",
   "metadata": {},
   "source": [
    "<h2 id=\"filter\">Filter</h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0519aef-9080-48d9-baef-7ea9710f4d06",
   "metadata": {},
   "source": [
    "Filters allow you to find complex patterns, the simplest filter is a string. In this section we will pass a string to a different filter method and Beautiful Soup will perform a match against that exact string.  Consider the following HTML of rocket launchs:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5bd1b23e-dcf7-4f5e-be26-95264cfda4c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "  <tr>\n",
       "    <td id='flight' >Flight No</td>\n",
       "    <td>Launch site</td> \n",
       "    <td>Payload mass</td>\n",
       "   </tr>\n",
       "  <tr> \n",
       "    <td>1</td>\n",
       "    <td><a href='https://en.wikipedia.org/wiki/Florida'>Florida</a></td>\n",
       "    <td>300 kg</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>2</td>\n",
       "    <td><a href='https://en.wikipedia.org/wiki/Texas'>Texas</a></td>\n",
       "    <td>94 kg</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>3</td>\n",
       "    <td><a href='https://en.wikipedia.org/wiki/Florida'>Florida</a> </td>\n",
       "    <td>80 kg</td>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<table>\n",
    "  <tr>\n",
    "    <td id='flight' >Flight No</td>\n",
    "    <td>Launch site</td> \n",
    "    <td>Payload mass</td>\n",
    "   </tr>\n",
    "  <tr> \n",
    "    <td>1</td>\n",
    "    <td><a href='https://en.wikipedia.org/wiki/Florida'>Florida</a></td>\n",
    "    <td>300 kg</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>2</td>\n",
    "    <td><a href='https://en.wikipedia.org/wiki/Texas'>Texas</a></td>\n",
    "    <td>94 kg</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>3</td>\n",
    "    <td><a href='https://en.wikipedia.org/wiki/Florida'>Florida</a> </td>\n",
    "    <td>80 kg</td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b96eca-c351-4be6-9447-7c25e6984d17",
   "metadata": {},
   "source": [
    "We can store it as a string in the variable <code>table</code>:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f191dd84-2a67-4e9f-b7df-7e1ab69b162e",
   "metadata": {},
   "outputs": [],
   "source": [
    "table=\"<table><tr><td id='flight' >Flight No</td><td>Launch site</td><td>Payload mass</td></tr><tr><td>1</td><td><a href='https://en.wikipedia.org/wiki/Florida'>Florida</a></td><td>300 kg</td></tr><tr><td>2</td><td><a href='https://en.wikipedia.org/wiki/Texas'>Texas</a></td><td>94 kg</td></tr><tr><td>3</td><td><a href='https://en.wikipedia.org/wiki/Florida'>Florida</a> </td><td>80 kg</td></tr></table>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "853b3c0f-22b2-4424-9d8a-8d7584299b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_bs = BeautifulSoup(table, \"html.parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb00c8d-7f37-40a8-b406-8353becbaa24",
   "metadata": {},
   "source": [
    "## find All\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc282e79-f7e6-4863-b90d-ea34249cec25",
   "metadata": {},
   "source": [
    "The <code>find_all()</code> method looks through a tag’s descendants and retrieves all descendants that match your filters.\n",
    "\n",
    "<p>\n",
    "The Method signature for <code>find_all(name, attrs, recursive, string, limit, **kwargs)<c/ode>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077b641d-dab5-4b7c-b759-c2e39a78de55",
   "metadata": {},
   "source": [
    "### Name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3fbef39-a544-496b-b86c-85e7b05ca08d",
   "metadata": {},
   "source": [
    "When we set the <code>name</code> parameter to a tag name, the method will extract all the tags with that name and its children.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "34cf5e0a-8140-41ba-a27b-61d195ca5218",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tr><td id=\"flight\">Flight No</td><td>Launch site</td><td>Payload mass</td></tr>,\n",
       " <tr><td>1</td><td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida</a></td><td>300 kg</td></tr>,\n",
       " <tr><td>2</td><td><a href=\"https://en.wikipedia.org/wiki/Texas\">Texas</a></td><td>94 kg</td></tr>,\n",
       " <tr><td>3</td><td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida</a> </td><td>80 kg</td></tr>]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_rows=table_bs.find_all('tr')\n",
    "table_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2c2a7e-beec-405a-9439-b7c14e9f38f0",
   "metadata": {},
   "source": [
    "The result is a Python Iterable just like a list, each element is a <code>tag</code> object:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "196e9d74-13f5-4133-bbea-3438b45f32ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tr><td id=\"flight\">Flight No</td><td>Launch site</td><td>Payload mass</td></tr>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_row =table_rows[0]\n",
    "first_row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f084c7-e459-470d-92fb-1d1903c6db2e",
   "metadata": {},
   "source": [
    "The type is <code>tag</code>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f4eb629d-e687-4844-b51b-18b7bee20b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bs4.element.Tag'>\n"
     ]
    }
   ],
   "source": [
    "print(type(first_row))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04daf4db-1e05-4d29-9503-dd1625792aa3",
   "metadata": {},
   "source": [
    "we can obtain the child\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b8c99fe0-febd-4d53-8ba2-8bf146624813",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<td id=\"flight\">Flight No</td>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_row.td"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d178d07-35fb-4754-b05c-d4b6f445a9d0",
   "metadata": {},
   "source": [
    "If we iterate through the list, each element corresponds to a row in the table:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f0a044d9-9292-40e2-a8de-a29aad3d5816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 0 is <tr><td id=\"flight\">Flight No</td><td>Launch site</td><td>Payload mass</td></tr>\n",
      "row 1 is <tr><td>1</td><td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida</a></td><td>300 kg</td></tr>\n",
      "row 2 is <tr><td>2</td><td><a href=\"https://en.wikipedia.org/wiki/Texas\">Texas</a></td><td>94 kg</td></tr>\n",
      "row 3 is <tr><td>3</td><td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida</a> </td><td>80 kg</td></tr>\n"
     ]
    }
   ],
   "source": [
    "for i,row in enumerate(table_rows):\n",
    "    print(\"row\",i,\"is\",row)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a778316f-4f6c-41ab-a18f-cb1c6b68fe99",
   "metadata": {},
   "source": [
    "As <code>row</code> is a <code>cell</code> object, we can apply the method <code>find_all</code> to it and extract table cells in the object <code>cells</code> using the tag <code>td</code>, this is all the children with the name <code>td</code>. The result is a list, each element corresponds to a cell and is a <code>Tag</code> object, we can iterate through this list as well. We can extract the content using the <code>string</code>  attribute.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "77681be5-f0da-47d8-8423-8a6ce9929874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 0\n",
      "colunm 0 cell <td id=\"flight\">Flight No</td>\n",
      "colunm 1 cell <td>Launch site</td>\n",
      "colunm 2 cell <td>Payload mass</td>\n",
      "row 1\n",
      "colunm 0 cell <td>1</td>\n",
      "colunm 1 cell <td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida</a></td>\n",
      "colunm 2 cell <td>300 kg</td>\n",
      "row 2\n",
      "colunm 0 cell <td>2</td>\n",
      "colunm 1 cell <td><a href=\"https://en.wikipedia.org/wiki/Texas\">Texas</a></td>\n",
      "colunm 2 cell <td>94 kg</td>\n",
      "row 3\n",
      "colunm 0 cell <td>3</td>\n",
      "colunm 1 cell <td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida</a> </td>\n",
      "colunm 2 cell <td>80 kg</td>\n"
     ]
    }
   ],
   "source": [
    "for i,row in enumerate(table_rows):\n",
    "    print(\"row\",i)\n",
    "    cells=row.find_all('td')\n",
    "    for j,cell in enumerate(cells):\n",
    "        print('colunm',j,\"cell\",cell)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf866ca-a9e1-4ca0-bee2-20bd89475457",
   "metadata": {},
   "source": [
    "If we use a list we can match against any item in that list.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2f8ee38e-4a7b-46cb-b943-2cbc012c3440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tr><td id=\"flight\">Flight No</td><td>Launch site</td><td>Payload mass</td></tr>,\n",
       " <td id=\"flight\">Flight No</td>,\n",
       " <td>Launch site</td>,\n",
       " <td>Payload mass</td>,\n",
       " <tr><td>1</td><td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida</a></td><td>300 kg</td></tr>,\n",
       " <td>1</td>,\n",
       " <td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida</a></td>,\n",
       " <td>300 kg</td>,\n",
       " <tr><td>2</td><td><a href=\"https://en.wikipedia.org/wiki/Texas\">Texas</a></td><td>94 kg</td></tr>,\n",
       " <td>2</td>,\n",
       " <td><a href=\"https://en.wikipedia.org/wiki/Texas\">Texas</a></td>,\n",
       " <td>94 kg</td>,\n",
       " <tr><td>3</td><td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida</a> </td><td>80 kg</td></tr>,\n",
       " <td>3</td>,\n",
       " <td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida</a> </td>,\n",
       " <td>80 kg</td>]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_input=table_bs .find_all(name=[\"tr\", \"td\"])\n",
    "list_input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06cb001-5767-4990-94f4-e28158608a62",
   "metadata": {},
   "source": [
    "## Attributes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598d9f83-fc90-46e0-8dae-e5449473bb17",
   "metadata": {},
   "source": [
    "If the argument is not recognized it will be turned into a filter on the tag’s attributes. For example the <code>id</code>  argument, Beautiful Soup will filter against each tag’s <code>id</code> attribute. For example, the first <code>td</code> elements have a value of <code>id</code> of <code>flight</code>, therefore we can filter based on that <code>id</code> value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "884811dc-2812-4233-aaab-c3725d96c63c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<td id=\"flight\">Flight No</td>]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_bs.find_all(id=\"flight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73965925-6616-424c-9e16-d54ff6f3722f",
   "metadata": {},
   "source": [
    "We can find all the elements that have links to the Florida Wikipedia page:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "683e7343-4342-4c59-b41c-2b100fa5ead2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a href=\"https://en.wikipedia.org/wiki/Florida\">Florida</a>,\n",
       " <a href=\"https://en.wikipedia.org/wiki/Florida\">Florida</a>]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_input=table_bs.find_all(href=\"https://en.wikipedia.org/wiki/Florida\")\n",
    "list_input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fda315c-3d9c-4b20-b930-6038ef294be0",
   "metadata": {},
   "source": [
    "If we set the  <code>href</code> attribute to True, regardless of what the value is, the code finds all tags with <code>href</code> value:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c35a6e0b-ea94-492e-96e9-e5337da68412",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a href=\"https://en.wikipedia.org/wiki/Florida\">Florida</a>,\n",
       " <a href=\"https://en.wikipedia.org/wiki/Texas\">Texas</a>,\n",
       " <a href=\"https://en.wikipedia.org/wiki/Florida\">Florida</a>]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_bs.find_all(href=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad26b1b-d430-46a6-98e4-baa69a5420af",
   "metadata": {},
   "source": [
    "There are other methods for dealing with attributes and other related methods; Check out the following <a href='https://www.crummy.com/software/BeautifulSoup/bs4/doc/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkPY0220ENSkillsNetwork23455606-2021-01-01#css-selectors'>link</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2105b04-842e-4960-9beb-e70bc8dc0077",
   "metadata": {},
   "source": [
    "<h3 id=\"exer_type\">Exercise: <code>find_all</code></h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6d76a9-127f-40e9-a063-3ed5c6c449eb",
   "metadata": {},
   "source": [
    "Using the logic above, find all the elements without <code>href</code> value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "40427f22-48b8-42e9-b9ff-3e701ff05f70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_bs.find_all('a', href = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d261ca-cba5-4657-9970-eb8a240e1a15",
   "metadata": {},
   "source": [
    "<details><summary>Click here for the solution</summary>\n",
    "\n",
    "```\n",
    "table_bs.find_all('a', href=False)\n",
    "\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28aaa584-ac93-4ceb-ba58-4cf959f0ce60",
   "metadata": {},
   "source": [
    "Using the soup object <code>soup</code>, find the element with the <code>id</code> attribute content set to <code>\"boldest\"</code>.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3978a865-a330-4df4-82c9-6dec21bc595b",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "ResultSet object has no attribute \"find_all\". You're probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[50]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43msoup\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfind_all\u001b[49m(\u001b[38;5;28mid\u001b[39m = \u001b[33m\"\u001b[39m\u001b[33mboldest\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Data Science Project\\.venv\\Lib\\site-packages\\bs4\\element.py:3203\u001b[39m, in \u001b[36mResultSet.__getattr__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3201\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key: \u001b[38;5;28mstr\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   3202\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Raise a helpful exception to explain a common code fix.\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3203\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[32m   3204\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\u001b[33mResultSet object has no attribute \u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m. You\u001b[39m\u001b[33m'\u001b[39m\u001b[33mre probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m   3205\u001b[39m     )\n",
      "\u001b[31mAttributeError\u001b[39m: ResultSet object has no attribute \"find_all\". You're probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?"
     ]
    }
   ],
   "source": [
    "soup.find_all(id = \"boldest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f07fc37-f456-49a9-a026-c5d9712ab51a",
   "metadata": {},
   "source": [
    "<details><summary>Click here for the solution</summary>\n",
    "\n",
    "```\n",
    "soup.find_all(id=\"boldest\")\n",
    "\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba7d02a-57b0-4e1f-9b91-fb78baaff709",
   "metadata": {},
   "source": [
    "### string\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a0bbf0-af4d-4073-ba2a-ff426a3ba034",
   "metadata": {},
   "source": [
    "With string you can search for strings instead of tags, where we find all the elments with Florida:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "09e93f3c-3bfc-4d8a-a6d2-df900e52ca21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Florida', 'Florida']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_bs.find_all(string=\"Florida\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f07e79e-0bb1-4c56-b822-ea94aed004ed",
   "metadata": {},
   "source": [
    "## find\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2562e464-ce57-495f-b77b-ee96489c3ea9",
   "metadata": {},
   "source": [
    "The <code>find_all()</code> method scans the entire document looking for results, it’s if you are looking for one element you can use the <code>find()</code> method to find the first element in the document. Consider the following two table:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "23a5ff7a-12d8-45e2-bf4f-bce0268a803f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3>Rocket Launch </h3>\n",
       "\n",
       "<p>\n",
       "<table class='rocket'>\n",
       "  <tr>\n",
       "    <td>Flight No</td>\n",
       "    <td>Launch site</td> \n",
       "    <td>Payload mass</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>1</td>\n",
       "    <td>Florida</td>\n",
       "    <td>300 kg</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>2</td>\n",
       "    <td>Texas</td>\n",
       "    <td>94 kg</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>3</td>\n",
       "    <td>Florida </td>\n",
       "    <td>80 kg</td>\n",
       "  </tr>\n",
       "</table>\n",
       "</p>\n",
       "<p>\n",
       "\n",
       "<h3>Pizza Party  </h3>\n",
       "\n",
       "\n",
       "<table class='pizza'>\n",
       "  <tr>\n",
       "    <td>Pizza Place</td>\n",
       "    <td>Orders</td> \n",
       "    <td>Slices </td>\n",
       "   </tr>\n",
       "  <tr>\n",
       "    <td>Domino's Pizza</td>\n",
       "    <td>10</td>\n",
       "    <td>100</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>Little Caesars</td>\n",
       "    <td>12</td>\n",
       "    <td >144 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>Papa John's </td>\n",
       "    <td>15 </td>\n",
       "    <td>165</td>\n",
       "  </tr>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<h3>Rocket Launch </h3>\n",
    "\n",
    "<p>\n",
    "<table class='rocket'>\n",
    "  <tr>\n",
    "    <td>Flight No</td>\n",
    "    <td>Launch site</td> \n",
    "    <td>Payload mass</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>1</td>\n",
    "    <td>Florida</td>\n",
    "    <td>300 kg</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>2</td>\n",
    "    <td>Texas</td>\n",
    "    <td>94 kg</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>3</td>\n",
    "    <td>Florida </td>\n",
    "    <td>80 kg</td>\n",
    "  </tr>\n",
    "</table>\n",
    "</p>\n",
    "<p>\n",
    "\n",
    "<h3>Pizza Party  </h3>\n",
    "  \n",
    "    \n",
    "<table class='pizza'>\n",
    "  <tr>\n",
    "    <td>Pizza Place</td>\n",
    "    <td>Orders</td> \n",
    "    <td>Slices </td>\n",
    "   </tr>\n",
    "  <tr>\n",
    "    <td>Domino's Pizza</td>\n",
    "    <td>10</td>\n",
    "    <td>100</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Little Caesars</td>\n",
    "    <td>12</td>\n",
    "    <td >144 </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Papa John's </td>\n",
    "    <td>15 </td>\n",
    "    <td>165</td>\n",
    "  </tr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac81014-5d43-4962-a922-cabab26100e8",
   "metadata": {},
   "source": [
    "We store the HTML as a Python string and assign <code>two_tables</code>:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "dc07fdd4-81a9-4b93-83fc-02eb49509939",
   "metadata": {},
   "outputs": [],
   "source": [
    "two_tables=\"<h3>Rocket Launch </h3><p><table class='rocket'><tr><td>Flight No</td><td>Launch site</td> <td>Payload mass</td></tr><tr><td>1</td><td>Florida</td><td>300 kg</td></tr><tr><td>2</td><td>Texas</td><td>94 kg</td></tr><tr><td>3</td><td>Florida </td><td>80 kg</td></tr></table></p><p><h3>Pizza Party  </h3><table class='pizza'><tr><td>Pizza Place</td><td>Orders</td> <td>Slices </td></tr><tr><td>Domino's Pizza</td><td>10</td><td>100</td></tr><tr><td>Little Caesars</td><td>12</td><td >144 </td></tr><tr><td>Papa John's </td><td>15 </td><td>165</td></tr>\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df151d1-69aa-4738-89c5-01aff9dbf02a",
   "metadata": {},
   "source": [
    "We create a <code>BeautifulSoup</code> object  <code>two_tables_bs</code>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "db545efe-02d9-43ab-8b81-316dbcdb97ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "two_tables_bs= BeautifulSoup(two_tables, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8a7394-6ee9-49ba-9f63-141bf3cdae1d",
   "metadata": {},
   "source": [
    "We can find the first table using the tag name table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c5c92260-5981-4524-b90b-23ddca982c78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<table class=\"rocket\"><tr><td>Flight No</td><td>Launch site</td> <td>Payload mass</td></tr><tr><td>1</td><td>Florida</td><td>300 kg</td></tr><tr><td>2</td><td>Texas</td><td>94 kg</td></tr><tr><td>3</td><td>Florida </td><td>80 kg</td></tr></table>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_tables_bs.find(\"table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7d5072-fd4a-4073-8019-b3938190f18c",
   "metadata": {},
   "source": [
    "We can filter on the class attribute to find the second table, but because class is a keyword in Python, we add an underscore.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "31cb0772-0967-4bf7-9c0a-28614a1c4afb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<table class=\"pizza\"><tr><td>Pizza Place</td><td>Orders</td> <td>Slices </td></tr><tr><td>Domino's Pizza</td><td>10</td><td>100</td></tr><tr><td>Little Caesars</td><td>12</td><td>144 </td></tr><tr><td>Papa John's </td><td>15 </td><td>165</td></tr></table>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_tables_bs.find(\"table\",class_='pizza')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f9d264-3c48-406c-9b85-f4fa96cfc5ed",
   "metadata": {},
   "source": [
    "<h2 id=\"DSCW\">Downloading And Scraping The Contents Of A Web Page</h2> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e85df26-66a0-48b7-8040-37ae52a59f89",
   "metadata": {},
   "source": [
    "We Download the contents of the web page:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ae9a8ddc-eab3-4115-80c8-0d1a0a5ba414",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://www.ibm.com\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff79f12e-1766-47a3-87f9-adc55d905b9e",
   "metadata": {},
   "source": [
    "We use <code>get</code> to download the contents of the webpage in text format and store in a variable called <code>data</code>:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e25c3d43-a75d-4a5f-bd02-6301688f63e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data  = requests.get(url).text "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404c1f7b-8bb3-460e-a363-b66ea52f5f40",
   "metadata": {},
   "source": [
    "We create a <code>BeautifulSoup</code> object using the <code>BeautifulSoup</code> constructor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8d58864b-ef0d-4e30-bf4c-5cdb2ace57b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(data,\"html.parser\")  # create a soup object using the variable 'data'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8cf9e6-388e-46b9-8713-3b7358351bb6",
   "metadata": {},
   "source": [
    "Scrape all links\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f29abf0d-4715-49b5-bee3-960505b070b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.ibm.com/campaign/digital-sovereignty\n",
      "https://www.ibm.com/events/reg/flow/ibm/gg0zwumb/landing/page/landing?lnk=hprc1in\n",
      "https://www.ibm.com/events/reg/flow/ibm/xcuydomb/landing/page/landing?utm_source=ibmcom&utm_medium=web_IN&utm_campaign=instanawebinar&lnk=hprc2in\n",
      "https://www.ibm.com/products/spss-statistics?lnk=hprc3in\n",
      "https://www.ibm.com/case-studies/api-holdings?lnk=hprc4in\n",
      "https://www.ibm.com/products/offers-and-discounts\n",
      "https://www.ibm.com/case-studies/sixt?lnk=hpcs1us\n",
      "https://www.ibm.com/case-studies/scuderia-ferrari?lnk=hpcs2us\n",
      "https://www.ibm.com/case-studies/us-open?lnk=hpcs3us\n",
      "https://www.ibm.com/case-studies/avid-solutions-international?lnk=hpcs4us\n",
      "https://www.ibm.com/case-studies/ufc?lnk=hpcs5us\n",
      "https://www.ibm.com/community/ibm-techxchange-conference/?lnk=hpdev1us\n",
      "https://github.com/ibm-granite-community/granite-snack-cookbook?lnk=hpdev2us\n",
      "https://developer.ibm.com/technologies/artificial-intelligence/?lnk=hpdev3us\n",
      "https://www.ibm.com/account/reg/signup?formid=urx-51898&lnk=hpdev4us\n",
      "https://www.ibm.com/products/watsonx-orchestrate?lnk=hpdev5in\n",
      "https://research.ibm.com/blog/granite-vision-ocr-leaderboard?lnk=hpdev6us\n",
      "https://www.ibm.com/new/announcements/governing-ai-with-confidence-our-journey-with-watsonx-governance?lnk=hpdev7us\n",
      "https://www.ibm.com/products/maximo?lnk=hpdev8in\n",
      "https://www.ibm.com/software?lnk=hpfp1us\n",
      "https://www.ibm.com/solutions/ai-agents?lnk=hpfp2in\n",
      "https://www.ibm.com/solutions/data-and-ai?lnk=hpfp3in\n",
      "https://www.ibm.com/solutions/automation?lnk=hpfp4in\n",
      "https://www.ibm.com/solutions/hybrid-cloud?lnk=hpfp5in\n",
      "https://www.ibm.com/solutions/ai-models?lnk=hpfp6in\n",
      "https://www.ibm.com/solutions/analytics?lnk=hpfp7in\n",
      "https://www.ibm.com/solutions/security?lnk=hpfp8in\n",
      "https://www.ibm.com/consulting?lnk=hpfp9in\n",
      "https://www.ibm.com/events/reg/flow/ibm/xcuydomb/landing/page/landing?utm_source=ibmcom&utm_medium=web_IN&utm_campaign=instanawebinar\n",
      "https://www.ibm.com/in-en/about?lnk=hpii1in\n",
      "https://www.ibm.com/in-en/events/think?lnk=hpii1in\n",
      "https://research.ibm.com?lnk=hpii1in\n",
      "https://www.ibm.com/quantum?lnk=hpii1in\n",
      "https://www.ibm.com/in-en/careers?lnk=hpii1in\n",
      "https://skillsbuild.org?lnk=hpii1in\n",
      "https://www.ibm.com/in-en/careers?lnk=hpii1in\n",
      "https://skillsbuild.org?lnk=hpii1au\n",
      "https://in.newsroom.ibm.com/2025-08-07-India-Records-Highest-Average-Cost-of-a-Data-Breach-IBM\n",
      "https://in.newsroom.ibm.com/2025-10-31-IBM-Announces-Strategic-Collaboration-with-AICTE\n",
      "https://in.newsroom.ibm.com/Bharti-Airtel-announces-a-strategic-partnership-with-IBM-to-augment-Airtel-Cloud\n",
      "https://in.newsroom.ibm.com/Indian-Enterprises-Bet-Big-on-AI-Leadership-67-to-Appoint-CAIOs-Within-2-Years,-Finds-IBM-Study\n",
      "https://in.newsroom.ibm.com/2025-09-25-Unity-Small-Finance-Bank-Taps-IBM-to-Fast-Track-Customer-Experience-Innovation-with-Streamlined-Application-Management\n",
      "https://in.newsroom.ibm.com/2025-09-17-IBM-and-BharatGen-collaborate-to-accelerate-AI-adoption-in-India\n",
      "https://in.newsroom.ibm.com/2025-08-19-Vi-IBM-AI-collaboration\n",
      "https://in.newsroom.ibm.com/2025-08-13-IBM-unveils-new-India-client-experience-center-mumbai-and-Mahrashtra-quantum-initiatives\n"
     ]
    }
   ],
   "source": [
    "for link in soup.find_all('a',href=True):  # in html anchor/link is represented by the tag <a>\n",
    "\n",
    "    print(link.get('href'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f30c519-92f0-4b48-bdd6-23b22db06f2e",
   "metadata": {},
   "source": [
    "## Scrape  all images  Tags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b1d4c166-86ba-41cd-a429-c585c716b53e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<img alt=\"Illustration of digital security with padlocks, blocks, and spheres on an assembly line\" class=\"cmp-image__image\" height=\"1877\" itemprop=\"contentUrl\" loading=\"lazy\" src=\"https://assets.ibm.com/is/image/ibm/cover-1?ts=1763647522545&amp;dpr=off\" srcset=\"data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==\" title=\"Abstract neon geometric digital design\" width=\"2089\"/>\n",
      "https://assets.ibm.com/is/image/ibm/cover-1?ts=1763647522545&dpr=off\n",
      "<img alt=\"Isometric 3D render of microphone with headphones on top of a keyboard\" class=\"cmp-image__image\" height=\"360\" itemprop=\"contentUrl\" loading=\"lazy\" src=\"https://assets.ibm.com/is/image/ibm/5573fc12-84f8-4c00-ad47e1396fa83887?ts=1760359230840&amp;dpr=off\" srcset=\"data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==\" title=\"Microphone and headphones on webinar key\" width=\"480\"/>\n",
      "https://assets.ibm.com/is/image/ibm/5573fc12-84f8-4c00-ad47e1396fa83887?ts=1760359230840&dpr=off\n",
      "<img alt=\"Illustration of a man pointing to a chart with analytical graphs\" class=\"cmp-image__image\" height=\"1922\" itemprop=\"contentUrl\" loading=\"lazy\" src=\"https://assets.ibm.com/is/image/ibm/data-management-2?ts=1760359191872&amp;dpr=off\" srcset=\"data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==\" title=\"Man analyzing data on digital dashboard\" width=\"2561\"/>\n",
      "https://assets.ibm.com/is/image/ibm/data-management-2?ts=1760359191872&dpr=off\n",
      "<img alt=\"Woman sitting in front of monitors with graphs and analytical data, in modern office setting\" class=\"cmp-image__image\" height=\"320\" itemprop=\"contentUrl\" loading=\"lazy\" src=\"https://assets.ibm.com/is/image/ibm/SPSS_Statistics_Product_Card?ts=1763492404668&amp;dpr=off\" srcset=\"data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==\" title=\"Businesswoman analyzing financial data on screens\" width=\"444\"/>\n",
      "https://assets.ibm.com/is/image/ibm/SPSS_Statistics_Product_Card?ts=1763492404668&dpr=off\n",
      "<img alt=\"Isometric 3D render of Optimize IT technology\" class=\"cmp-image__image\" height=\"1200\" itemprop=\"contentUrl\" loading=\"lazy\" src=\"https://assets.ibm.com/is/image/ibm/ai_iso?ts=1760359061261&amp;dpr=off\" srcset=\"data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==\" title=\"Abstract tech design with circular elements\" width=\"1200\"/>\n",
      "https://assets.ibm.com/is/image/ibm/ai_iso?ts=1760359061261&dpr=off\n",
      "<img alt=\"Close-up of multiple people stacking hands together\" class=\"cmp-image__image\" height=\"1032\" itemprop=\"contentUrl\" loading=\"lazy\" src=\"https://assets.ibm.com/is/image/ibm/big-blue-for-you-leadspace-medium-crop?ts=1763648256756&amp;dpr=off\" srcset=\"data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==\" title=\"Shopping visuals with percentage symbols\" width=\"1393\"/>\n",
      "https://assets.ibm.com/is/image/ibm/big-blue-for-you-leadspace-medium-crop?ts=1763648256756&dpr=off\n",
      "<img alt=\"Person at a desk with an orange model car\" class=\"cmp-image__image\" height=\"960\" itemprop=\"contentUrl\" loading=\"lazy\" src=\"https://assets.ibm.com/is/image/ibm/sixt-smarter-business-case-study-regular-medium-ls?ts=1763034335430&amp;dpr=off\" srcset=\"data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==\" title=\"Person signing car lease agreement\" width=\"3168\"/>\n",
      "https://assets.ibm.com/is/image/ibm/sixt-smarter-business-case-study-regular-medium-ls?ts=1763034335430&dpr=off\n",
      "<img alt=\"IBM Ferrari logo lockup with Ferrari driver in background\" class=\"cmp-image__image\" height=\"1616\" itemprop=\"contentUrl\" loading=\"lazy\" src=\"https://assets.ibm.com/is/image/ibm/ibm_ferrari_video_thumb_01?ts=1763034336018&amp;dpr=off\" srcset=\"data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==\" title=\"Ferrari Driver in Racing Gear with IBM Logo\" width=\"2872\"/>\n",
      "https://assets.ibm.com/is/image/ibm/ibm_ferrari_video_thumb_01?ts=1763034336018&dpr=off\n",
      "<img alt=\"US Open - crowd and court\" class=\"cmp-image__image\" height=\"1969\" itemprop=\"contentUrl\" loading=\"lazy\" src=\"https://assets.ibm.com/is/image/ibm/us-open-crowd-court?ts=1763034336662&amp;dpr=off\" srcset=\"data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==\" title=\"Crowded tennis stadium during live match\" width=\"3584\"/>\n",
      "https://assets.ibm.com/is/image/ibm/us-open-crowd-court?ts=1763034336662&dpr=off\n",
      "<img alt=\"Two horticulturists looking over plants\" class=\"cmp-image__image\" height=\"1200\" itemprop=\"contentUrl\" loading=\"lazy\" src=\"https://assets.ibm.com/is/image/ibm/watsonx-orchestrate_avid-solutions_dco-native?ts=1763034337215&amp;dpr=off\" srcset=\"data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==\" title=\"Women harvesting greens in indoor farm\" width=\"1200\"/>\n",
      "https://assets.ibm.com/is/image/ibm/watsonx-orchestrate_avid-solutions_dco-native?ts=1763034337215&dpr=off\n",
      "<img alt=\"Octagon with the UFC and IBM logo\" class=\"cmp-image__image\" height=\"1000\" itemprop=\"contentUrl\" loading=\"lazy\" src=\"https://assets.ibm.com/is/image/ibm/1731592760476?ts=1763492256961&amp;dpr=off\" srcset=\"data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==\" width=\"800\"/>\n",
      "https://assets.ibm.com/is/image/ibm/1731592760476?ts=1763492256961&dpr=off\n",
      "<img alt=\"Isometric 3D render of microphone with headphones on top of a keyboard\" class=\"cmp-image__image\" height=\"360\" itemprop=\"contentUrl\" loading=\"lazy\" src=\"https://assets.ibm.com/is/image/ibm/5573fc12-84f8-4c00-ad47e1396fa83887?ts=1761736238789&amp;dpr=off\" srcset=\"data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==\" title=\"Microphone and headphones on webinar key\" width=\"480\"/>\n",
      "https://assets.ibm.com/is/image/ibm/5573fc12-84f8-4c00-ad47e1396fa83887?ts=1761736238789&dpr=off\n",
      "<img alt=\"Illustration of an eye with connecting lines to data\" class=\"cmp-image__image\" height=\"2961\" itemprop=\"contentUrl\" loading=\"lazy\" src=\"https://assets.ibm.com/is/image/ibm/watson-discovery_eye-connection_1x1_padding?ts=1758831124391&amp;dpr=off\" srcset=\"data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==\" width=\"2961\"/>\n",
      "https://assets.ibm.com/is/image/ibm/watson-discovery_eye-connection_1x1_padding?ts=1758831124391&dpr=off\n"
     ]
    }
   ],
   "source": [
    "for link in soup.find_all('img'):# in html image is represented by the tag <img>\n",
    "    print(link)\n",
    "    print(link.get('src'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2eb3a15-149f-43db-8c7b-ac684141ecd0",
   "metadata": {},
   "source": [
    "## Scrape data from HTML tables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e79c9bab-102d-4107-8ad7-2d6abbcb6f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The below url contains an html table with data about colors and color codes.\n",
    "url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DA0321EN-SkillsNetwork/labs/datasets/HTMLColorCodes.html\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667196c2-9224-4af8-b4a6-d17bc82a787b",
   "metadata": {},
   "source": [
    "Before proceeding to scrape a web site, you need to examine the contents, and the way data is organized on the website. Open the above url in your browser and check how many rows and columns are there in the color table.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d7e76363-7b72-4085-81aa-5b76bc14ef50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the contents of the webpage in text format and store in a variable called data\n",
    "data  = requests.get(url).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5930565a-b93f-4b79-b959-ccde2b934cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(data,\"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "38f1467b-fb7a-4b0c-bfb8-7fc22c460509",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find a html table in the web page\n",
    "table = soup.find('table') # in html table is represented by the tag <table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e836ef88-d462-4bb6-862a-691648d7ac78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Color Name--->None\n",
      "lightsalmon--->#FFA07A\n",
      "salmon--->#FA8072\n",
      "darksalmon--->#E9967A\n",
      "lightcoral--->#F08080\n",
      "coral--->#FF7F50\n",
      "tomato--->#FF6347\n",
      "orangered--->#FF4500\n",
      "gold--->#FFD700\n",
      "orange--->#FFA500\n",
      "darkorange--->#FF8C00\n",
      "lightyellow--->#FFFFE0\n",
      "lemonchiffon--->#FFFACD\n",
      "papayawhip--->#FFEFD5\n",
      "moccasin--->#FFE4B5\n",
      "peachpuff--->#FFDAB9\n",
      "palegoldenrod--->#EEE8AA\n",
      "khaki--->#F0E68C\n",
      "darkkhaki--->#BDB76B\n",
      "yellow--->#FFFF00\n",
      "lawngreen--->#7CFC00\n",
      "chartreuse--->#7FFF00\n",
      "limegreen--->#32CD32\n",
      "lime--->#00FF00\n",
      "forestgreen--->#228B22\n",
      "green--->#008000\n",
      "powderblue--->#B0E0E6\n",
      "lightblue--->#ADD8E6\n",
      "lightskyblue--->#87CEFA\n",
      "skyblue--->#87CEEB\n",
      "deepskyblue--->#00BFFF\n",
      "lightsteelblue--->#B0C4DE\n",
      "dodgerblue--->#1E90FF\n"
     ]
    }
   ],
   "source": [
    "#Get all rows from the table\n",
    "for row in table.find_all('tr'): # in html table row is represented by the tag <tr>\n",
    "    # Get all columns in each row.\n",
    "    cols = row.find_all('td') # in html a column is represented by the tag <td>\n",
    "    color_name = cols[2].string # store the value in column 3 as color_name\n",
    "    color_code = cols[3].string # store the value in column 4 as color_code\n",
    "    print(\"{}--->{}\".format(color_name,color_code))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85045ed-a0e8-4bb1-be4f-c1b56828877f",
   "metadata": {},
   "source": [
    "## Scrape data from HTML tables into a DataFrame using BeautifulSoup and Pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "884a1785-6b02-40e8-96e1-ad41a132766b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "37a34cd0-e146-49a8-bdbd-235e134d03d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The below url contains html tables with data about world population.\n",
    "url = \"https://en.wikipedia.org/wiki/World_population\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e95abf-1eb6-40a6-bd8b-207753bbe64b",
   "metadata": {},
   "source": [
    "Before proceeding to scrape a web site, you need to examine the contents, and the way data is organized on the website. Open the above url in your browser and check the tables on the webpage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b9ebec5d-91aa-4c3f-a8f6-8c10edaaace6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the contents of the webpage in text format and store in a variable called data\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "                  \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "                  \"Chrome/91.0.4472.124 Safari/537.36\"\n",
    "}\n",
    "\n",
    "data  = requests.get(url, headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "38e8eaca-a0c8-446c-8979-d41d45dabf4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(data.text,\"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "50ea6bf3-046d-4e84-8f27-74b2f4e5354b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find all html tables in the web page\n",
    "tables = soup.find_all('table') # in html table is represented by the tag <table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d7a816eb-d831-4028-8114-cf7c6498e998",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can see how many tables were found by checking the length of the tables list\n",
    "len(tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e7a145-cebb-4350-8486-e174462a8837",
   "metadata": {},
   "source": [
    "Assume that we are looking for the `10 most densly populated countries` table, we can look through the tables list and find the right one we are look for based on the data in each table or we can search for the table name if it is in the table but this option might not always work.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "42093db3-8b3d-49f4-9016-6cd4ba85e278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "for index,table in enumerate(tables):\n",
    "    if (\"10 most densely populated countries\" in str(table)):\n",
    "        table_index = index\n",
    "print(table_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da581f4-a403-4187-aa25-250ffb8f77b8",
   "metadata": {},
   "source": [
    "See if you can locate the table name of the table, `10 most densly populated countries`, below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b2e38241-770d-4ef3-9528-c4e66c87e66b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<table class=\"wikitable sortable\" style=\"text-align:right\">\n",
      " <caption>\n",
      "  10 most densely populated countries\n",
      "  <small>\n",
      "   (with population above 5 million)\n",
      "  </small>\n",
      "  <sup class=\"reference\" id=\"cite_ref-:10_106-0\">\n",
      "   <a href=\"#cite_note-:10-106\">\n",
      "    <span class=\"cite-bracket\">\n",
      "     [\n",
      "    </span>\n",
      "    101\n",
      "    <span class=\"cite-bracket\">\n",
      "     ]\n",
      "    </span>\n",
      "   </a>\n",
      "  </sup>\n",
      " </caption>\n",
      " <tbody>\n",
      "  <tr>\n",
      "   <th scope=\"col\">\n",
      "    Rank\n",
      "   </th>\n",
      "   <th scope=\"col\">\n",
      "    Country\n",
      "   </th>\n",
      "   <th scope=\"col\">\n",
      "    Population\n",
      "   </th>\n",
      "   <th scope=\"col\">\n",
      "    Area\n",
      "    <br/>\n",
      "    <small>\n",
      "     (km\n",
      "     <sup>\n",
      "      2\n",
      "     </sup>\n",
      "     )\n",
      "    </small>\n",
      "   </th>\n",
      "   <th scope=\"col\">\n",
      "    Density\n",
      "    <br/>\n",
      "    <small>\n",
      "     (pop/km\n",
      "     <sup>\n",
      "      2\n",
      "     </sup>\n",
      "     )\n",
      "    </small>\n",
      "   </th>\n",
      "  </tr>\n",
      "  <tr>\n",
      "   <td>\n",
      "    1\n",
      "   </td>\n",
      "   <td align=\"left\">\n",
      "    <span class=\"flagicon nowrap\">\n",
      "     <span class=\"mw-image-border\" typeof=\"mw:File\">\n",
      "      <span>\n",
      "       <img alt=\"\" class=\"mw-file-element\" data-file-height=\"600\" data-file-width=\"900\" decoding=\"async\" height=\"15\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/4/48/Flag_of_Singapore.svg/40px-Flag_of_Singapore.svg.png\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/4/48/Flag_of_Singapore.svg/60px-Flag_of_Singapore.svg.png 2x\" width=\"23\"/>\n",
      "      </span>\n",
      "     </span>\n",
      "    </span>\n",
      "    <a href=\"/wiki/Singapore\" title=\"Singapore\">\n",
      "     Singapore\n",
      "    </a>\n",
      "   </td>\n",
      "   <td>\n",
      "    5,921,231\n",
      "   </td>\n",
      "   <td>\n",
      "    719\n",
      "   </td>\n",
      "   <td>\n",
      "    8,235\n",
      "   </td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "   <td>\n",
      "    2\n",
      "   </td>\n",
      "   <td align=\"left\">\n",
      "    <span class=\"flagicon nowrap\">\n",
      "     <span class=\"mw-image-border\" typeof=\"mw:File\">\n",
      "      <span>\n",
      "       <img alt=\"\" class=\"mw-file-element\" data-file-height=\"307\" data-file-width=\"512\" decoding=\"async\" height=\"14\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/f/f9/Flag_of_Bangladesh.svg/40px-Flag_of_Bangladesh.svg.png\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/f/f9/Flag_of_Bangladesh.svg/60px-Flag_of_Bangladesh.svg.png 2x\" width=\"23\"/>\n",
      "      </span>\n",
      "     </span>\n",
      "    </span>\n",
      "    <a href=\"/wiki/Bangladesh\" title=\"Bangladesh\">\n",
      "     Bangladesh\n",
      "    </a>\n",
      "   </td>\n",
      "   <td>\n",
      "    165,650,475\n",
      "   </td>\n",
      "   <td>\n",
      "    148,460\n",
      "   </td>\n",
      "   <td>\n",
      "    1,116\n",
      "   </td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "   <td>\n",
      "    3\n",
      "   </td>\n",
      "   <td align=\"left\">\n",
      "    <p>\n",
      "     <span class=\"flagicon nowrap\">\n",
      "      <span class=\"mw-image-border\" typeof=\"mw:File\">\n",
      "       <span>\n",
      "        <img alt=\"\" class=\"mw-file-element\" data-file-height=\"600\" data-file-width=\"1200\" decoding=\"async\" height=\"12\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/0/00/Flag_of_Palestine.svg/40px-Flag_of_Palestine.svg.png\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/0/00/Flag_of_Palestine.svg/60px-Flag_of_Palestine.svg.png 2x\" width=\"23\"/>\n",
      "       </span>\n",
      "      </span>\n",
      "     </span>\n",
      "     <a href=\"/wiki/Palestine\" title=\"Palestine\">\n",
      "      Palestine\n",
      "     </a>\n",
      "     <sup class=\"reference\" id=\"cite_ref-107\">\n",
      "      <a href=\"#cite_note-107\">\n",
      "       <span class=\"cite-bracket\">\n",
      "        [\n",
      "       </span>\n",
      "       note 3\n",
      "       <span class=\"cite-bracket\">\n",
      "        ]\n",
      "       </span>\n",
      "      </a>\n",
      "     </sup>\n",
      "     <sup class=\"reference\" id=\"cite_ref-108\">\n",
      "      <a href=\"#cite_note-108\">\n",
      "       <span class=\"cite-bracket\">\n",
      "        [\n",
      "       </span>\n",
      "       102\n",
      "       <span class=\"cite-bracket\">\n",
      "        ]\n",
      "       </span>\n",
      "      </a>\n",
      "     </sup>\n",
      "    </p>\n",
      "   </td>\n",
      "   <td>\n",
      "    5,223,000\n",
      "   </td>\n",
      "   <td>\n",
      "    6,025\n",
      "   </td>\n",
      "   <td>\n",
      "    867\n",
      "   </td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "   <td>\n",
      "    4\n",
      "   </td>\n",
      "   <td align=\"left\">\n",
      "    <span class=\"flagicon nowrap\">\n",
      "     <span class=\"mw-image-border\" typeof=\"mw:File\">\n",
      "      <span>\n",
      "       <img alt=\"\" class=\"mw-file-element\" data-file-height=\"600\" data-file-width=\"900\" decoding=\"async\" height=\"15\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/7/72/Flag_of_the_Republic_of_China.svg/40px-Flag_of_the_Republic_of_China.svg.png\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/7/72/Flag_of_the_Republic_of_China.svg/60px-Flag_of_the_Republic_of_China.svg.png 2x\" width=\"23\"/>\n",
      "      </span>\n",
      "     </span>\n",
      "    </span>\n",
      "    <a href=\"/wiki/Taiwan\" title=\"Taiwan\">\n",
      "     Taiwan\n",
      "    </a>\n",
      "    <sup class=\"reference\" id=\"cite_ref-109\">\n",
      "     <a href=\"#cite_note-109\">\n",
      "      <span class=\"cite-bracket\">\n",
      "       [\n",
      "      </span>\n",
      "      note 4\n",
      "      <span class=\"cite-bracket\">\n",
      "       ]\n",
      "      </span>\n",
      "     </a>\n",
      "    </sup>\n",
      "   </td>\n",
      "   <td>\n",
      "    23,580,712\n",
      "   </td>\n",
      "   <td>\n",
      "    35,980\n",
      "   </td>\n",
      "   <td>\n",
      "    655\n",
      "   </td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "   <td>\n",
      "    5\n",
      "   </td>\n",
      "   <td align=\"left\">\n",
      "    <span class=\"flagicon nowrap\">\n",
      "     <span class=\"mw-image-border\" typeof=\"mw:File\">\n",
      "      <span>\n",
      "       <img alt=\"\" class=\"mw-file-element\" data-file-height=\"600\" data-file-width=\"900\" decoding=\"async\" height=\"15\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/0/09/Flag_of_South_Korea.svg/40px-Flag_of_South_Korea.svg.png\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/0/09/Flag_of_South_Korea.svg/60px-Flag_of_South_Korea.svg.png 2x\" width=\"23\"/>\n",
      "      </span>\n",
      "     </span>\n",
      "    </span>\n",
      "    <a href=\"/wiki/South_Korea\" title=\"South Korea\">\n",
      "     South Korea\n",
      "    </a>\n",
      "   </td>\n",
      "   <td>\n",
      "    51,844,834\n",
      "   </td>\n",
      "   <td>\n",
      "    99,720\n",
      "   </td>\n",
      "   <td>\n",
      "    520\n",
      "   </td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "   <td>\n",
      "    6\n",
      "   </td>\n",
      "   <td align=\"left\">\n",
      "    <span class=\"flagicon nowrap\">\n",
      "     <span class=\"mw-image-border\" typeof=\"mw:File\">\n",
      "      <span>\n",
      "       <img alt=\"\" class=\"mw-file-element\" data-file-height=\"1920\" data-file-width=\"2880\" decoding=\"async\" height=\"15\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/5/59/Flag_of_Lebanon.svg/40px-Flag_of_Lebanon.svg.png\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/5/59/Flag_of_Lebanon.svg/60px-Flag_of_Lebanon.svg.png 2x\" width=\"23\"/>\n",
      "      </span>\n",
      "     </span>\n",
      "    </span>\n",
      "    <a href=\"/wiki/Lebanon\" title=\"Lebanon\">\n",
      "     Lebanon\n",
      "    </a>\n",
      "   </td>\n",
      "   <td>\n",
      "    5,296,814\n",
      "   </td>\n",
      "   <td>\n",
      "    10,400\n",
      "   </td>\n",
      "   <td>\n",
      "    509\n",
      "   </td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "   <td>\n",
      "    7\n",
      "   </td>\n",
      "   <td align=\"left\">\n",
      "    <span class=\"flagicon nowrap\">\n",
      "     <span class=\"mw-image-border\" typeof=\"mw:File\">\n",
      "      <span>\n",
      "       <img alt=\"\" class=\"mw-file-element\" data-file-height=\"600\" data-file-width=\"900\" decoding=\"async\" height=\"15\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/1/17/Flag_of_Rwanda.svg/40px-Flag_of_Rwanda.svg.png\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/1/17/Flag_of_Rwanda.svg/60px-Flag_of_Rwanda.svg.png 2x\" width=\"23\"/>\n",
      "      </span>\n",
      "     </span>\n",
      "    </span>\n",
      "    <a href=\"/wiki/Rwanda\" title=\"Rwanda\">\n",
      "     Rwanda\n",
      "    </a>\n",
      "   </td>\n",
      "   <td>\n",
      "    13,173,730\n",
      "   </td>\n",
      "   <td>\n",
      "    26,338\n",
      "   </td>\n",
      "   <td>\n",
      "    500\n",
      "   </td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "   <td>\n",
      "    8\n",
      "   </td>\n",
      "   <td align=\"left\">\n",
      "    <span class=\"flagicon nowrap\">\n",
      "     <span class=\"mw-image-border\" typeof=\"mw:File\">\n",
      "      <span>\n",
      "       <img alt=\"\" class=\"mw-file-element\" data-file-height=\"600\" data-file-width=\"1000\" decoding=\"async\" height=\"14\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/5/50/Flag_of_Burundi.svg/40px-Flag_of_Burundi.svg.png\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/5/50/Flag_of_Burundi.svg/60px-Flag_of_Burundi.svg.png 2x\" width=\"23\"/>\n",
      "      </span>\n",
      "     </span>\n",
      "    </span>\n",
      "    <a href=\"/wiki/Burundi\" title=\"Burundi\">\n",
      "     Burundi\n",
      "    </a>\n",
      "   </td>\n",
      "   <td>\n",
      "    12,696,478\n",
      "   </td>\n",
      "   <td>\n",
      "    27,830\n",
      "   </td>\n",
      "   <td>\n",
      "    456\n",
      "   </td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "   <td>\n",
      "    9\n",
      "   </td>\n",
      "   <td align=\"left\">\n",
      "    <span class=\"flagicon nowrap\">\n",
      "     <span class=\"mw-image-border\" typeof=\"mw:File\">\n",
      "      <span>\n",
      "       <img alt=\"\" class=\"mw-file-element\" data-file-height=\"800\" data-file-width=\"1100\" decoding=\"async\" height=\"15\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/d/d4/Flag_of_Israel.svg/40px-Flag_of_Israel.svg.png\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/d/d4/Flag_of_Israel.svg/60px-Flag_of_Israel.svg.png 2x\" width=\"21\"/>\n",
      "      </span>\n",
      "     </span>\n",
      "    </span>\n",
      "    <a href=\"/wiki/Israel\" title=\"Israel\">\n",
      "     Israel\n",
      "    </a>\n",
      "   </td>\n",
      "   <td>\n",
      "    9,402,617\n",
      "   </td>\n",
      "   <td>\n",
      "    21,937\n",
      "   </td>\n",
      "   <td>\n",
      "    429\n",
      "   </td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "   <td>\n",
      "    10\n",
      "   </td>\n",
      "   <td align=\"left\">\n",
      "    <span class=\"flagicon nowrap\">\n",
      "     <span class=\"mw-image-border\" typeof=\"mw:File\">\n",
      "      <span>\n",
      "       <img alt=\"\" class=\"mw-file-element\" data-file-height=\"600\" data-file-width=\"900\" decoding=\"async\" height=\"15\" src=\"//upload.wikimedia.org/wikipedia/en/thumb/4/41/Flag_of_India.svg/40px-Flag_of_India.svg.png\" srcset=\"//upload.wikimedia.org/wikipedia/en/thumb/4/41/Flag_of_India.svg/60px-Flag_of_India.svg.png 2x\" width=\"23\"/>\n",
      "      </span>\n",
      "     </span>\n",
      "    </span>\n",
      "    <a href=\"/wiki/India\" title=\"India\">\n",
      "     India\n",
      "    </a>\n",
      "   </td>\n",
      "   <td>\n",
      "    1,389,637,446\n",
      "   </td>\n",
      "   <td>\n",
      "    3,287,263\n",
      "   </td>\n",
      "   <td>\n",
      "    423\n",
      "   </td>\n",
      "  </tr>\n",
      " </tbody>\n",
      "</table>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tables[table_index].prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8f607067-dc26-4a64-b23a-7e931f622bc1",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[32m~\\AppData\\Local\\Temp\\ipykernel_20240\\394869253.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      7\u001b[39m         country = col[\u001b[32m1\u001b[39m].text\n\u001b[32m      8\u001b[39m         population = col[\u001b[32m2\u001b[39m].text.strip()\n\u001b[32m      9\u001b[39m         area = col[\u001b[32m3\u001b[39m].text.strip()\n\u001b[32m     10\u001b[39m         density = col[\u001b[32m4\u001b[39m].text.strip()\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m         population_data = population_data.append({\u001b[33m\"Rank\"\u001b[39m:rank, \u001b[33m\"Country\"\u001b[39m:country, \u001b[33m\"Population\"\u001b[39m:population, \u001b[33m\"Area\"\u001b[39m:area, \u001b[33m\"Density\"\u001b[39m:density}, ignore_index=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     12\u001b[39m \n\u001b[32m     13\u001b[39m population_data\n",
      "\u001b[32md:\\Data Science Project\\.venv\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   6317\u001b[39m             \u001b[38;5;28;01mand\u001b[39;00m name \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01min\u001b[39;00m self._accessors\n\u001b[32m   6318\u001b[39m             \u001b[38;5;28;01mand\u001b[39;00m self._info_axis._can_hold_identifiers_and_holds_name(name)\n\u001b[32m   6319\u001b[39m         ):\n\u001b[32m   6320\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m self[name]\n\u001b[32m-> \u001b[39m\u001b[32m6321\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m object.__getattribute__(self, name)\n",
      "\u001b[31mAttributeError\u001b[39m: 'DataFrame' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "population_data = pd.DataFrame(columns=[\"Rank\", \"Country\", \"Population\", \"Area\", \"Density\"])\n",
    "\n",
    "for row in tables[table_index].tbody.find_all(\"tr\"):\n",
    "    col = row.find_all(\"td\")\n",
    "    if (col != []):\n",
    "        rank = col[0].text\n",
    "        country = col[1].text\n",
    "        population = col[2].text.strip()\n",
    "        area = col[3].text.strip()\n",
    "        density = col[4].text.strip()\n",
    "        population_data = population_data.append({\"Rank\":rank, \"Country\":country, \"Population\":population, \"Area\":area, \"Density\":density}, ignore_index=True)\n",
    "\n",
    "population_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422eee3d-38be-47ea-9743-f9e6a6dcb68d",
   "metadata": {},
   "source": [
    "## Scrape data from HTML tables into a DataFrame using BeautifulSoup and read_html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b159734d-2631-48a7-a875-0baa200d34a0",
   "metadata": {},
   "source": [
    "Using the same `url`, `data`, `soup`, and `tables` object as in the last section we can use the `read_html` function to create a DataFrame.\n",
    "\n",
    "Remember the table we need is located in `tables[table_index]`\n",
    "\n",
    "We can now use the `pandas` function `read_html` and give it the string version of the table as well as the `flavor` which is the parsing engine `bs4`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "885591a8-49ba-4916-9805-e0a687d5a60f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\epics\\AppData\\Local\\Temp\\ipykernel_20240\\4059676793.py:1: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  pd.read_html(str(tables[5]), flavor='bs4')\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Missing optional dependency 'html5lib'.  Use pip or conda to install html5lib.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Data Science Project\\.venv\\Lib\\site-packages\\pandas\\compat\\_optional.py:135\u001b[39m, in \u001b[36mimport_optional_dependency\u001b[39m\u001b[34m(name, extra, errors, min_version)\u001b[39m\n\u001b[32m    134\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m135\u001b[39m     module = \u001b[43mimportlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Python314\\Lib\\importlib\\__init__.py:88\u001b[39m, in \u001b[36mimport_module\u001b[39m\u001b[34m(name, package)\u001b[39m\n\u001b[32m     87\u001b[39m         level += \u001b[32m1\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1398\u001b[39m, in \u001b[36m_gcd_import\u001b[39m\u001b[34m(name, package, level)\u001b[39m\n\u001b[32m   1397\u001b[39m     name = _resolve_name(name, package, level)\n\u001b[32m-> \u001b[39m\u001b[32m1398\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_find_and_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_gcd_import\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1371\u001b[39m, in \u001b[36m_find_and_load\u001b[39m\u001b[34m(name, import_)\u001b[39m\n\u001b[32m   1370\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m module \u001b[38;5;129;01mis\u001b[39;00m _NEEDS_LOADING:\n\u001b[32m-> \u001b[39m\u001b[32m1371\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_find_and_load_unlocked\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimport_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1373\u001b[39m \u001b[38;5;66;03m# Optimization: only call _bootstrap._lock_unlock_module() if\u001b[39;00m\n\u001b[32m   1374\u001b[39m \u001b[38;5;66;03m# module.__spec__._initializing is True.\u001b[39;00m\n\u001b[32m   1375\u001b[39m \u001b[38;5;66;03m# NOTE: because of this, initializing must be set *before*\u001b[39;00m\n\u001b[32m   1376\u001b[39m \u001b[38;5;66;03m# putting the new module in sys.modules.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1335\u001b[39m, in \u001b[36m_find_and_load_unlocked\u001b[39m\u001b[34m(name, import_)\u001b[39m\n\u001b[32m   1334\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m spec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1335\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_ERR_MSG_PREFIX\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m'\u001b[39m, name=name)\n\u001b[32m   1336\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'html5lib'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[79]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_html\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtables\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflavor\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mbs4\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Data Science Project\\.venv\\Lib\\site-packages\\pandas\\io\\html.py:1240\u001b[39m, in \u001b[36mread_html\u001b[39m\u001b[34m(io, match, flavor, header, index_col, skiprows, attrs, parse_dates, thousands, encoding, decimal, converters, na_values, keep_default_na, displayed_only, extract_links, dtype_backend, storage_options)\u001b[39m\n\u001b[32m   1224\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[32m   1225\u001b[39m     [\n\u001b[32m   1226\u001b[39m         is_file_like(io),\n\u001b[32m   (...)\u001b[39m\u001b[32m   1230\u001b[39m     ]\n\u001b[32m   1231\u001b[39m ):\n\u001b[32m   1232\u001b[39m     warnings.warn(\n\u001b[32m   1233\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPassing literal html to \u001b[39m\u001b[33m'\u001b[39m\u001b[33mread_html\u001b[39m\u001b[33m'\u001b[39m\u001b[33m is deprecated and \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1234\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mwill be removed in a future version. To read from a \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1237\u001b[39m         stacklevel=find_stack_level(),\n\u001b[32m   1238\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1240\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_parse\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1241\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflavor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mflavor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1242\u001b[39m \u001b[43m    \u001b[49m\u001b[43mio\u001b[49m\u001b[43m=\u001b[49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1243\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmatch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1244\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1245\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1246\u001b[39m \u001b[43m    \u001b[49m\u001b[43mskiprows\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskiprows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1247\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1248\u001b[39m \u001b[43m    \u001b[49m\u001b[43mthousands\u001b[49m\u001b[43m=\u001b[49m\u001b[43mthousands\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1249\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1250\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1251\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecimal\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecimal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1252\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconverters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconverters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1253\u001b[39m \u001b[43m    \u001b[49m\u001b[43mna_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mna_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1254\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkeep_default_na\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeep_default_na\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1255\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdisplayed_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdisplayed_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1256\u001b[39m \u001b[43m    \u001b[49m\u001b[43mextract_links\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextract_links\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1257\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1258\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1259\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Data Science Project\\.venv\\Lib\\site-packages\\pandas\\io\\html.py:971\u001b[39m, in \u001b[36m_parse\u001b[39m\u001b[34m(flavor, io, match, attrs, encoding, displayed_only, extract_links, storage_options, **kwargs)\u001b[39m\n\u001b[32m    969\u001b[39m retained = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    970\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m flav \u001b[38;5;129;01min\u001b[39;00m flavor:\n\u001b[32m--> \u001b[39m\u001b[32m971\u001b[39m     parser = \u001b[43m_parser_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mflav\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    972\u001b[39m     p = parser(\n\u001b[32m    973\u001b[39m         io,\n\u001b[32m    974\u001b[39m         compiled_match,\n\u001b[32m   (...)\u001b[39m\u001b[32m    979\u001b[39m         storage_options,\n\u001b[32m    980\u001b[39m     )\n\u001b[32m    982\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Data Science Project\\.venv\\Lib\\site-packages\\pandas\\io\\html.py:915\u001b[39m, in \u001b[36m_parser_dispatch\u001b[39m\u001b[34m(flavor)\u001b[39m\n\u001b[32m    910\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    911\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(flavor)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m is not a valid flavor, valid flavors are \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalid_parsers\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    912\u001b[39m     )\n\u001b[32m    914\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m flavor \u001b[38;5;129;01min\u001b[39;00m (\u001b[33m\"\u001b[39m\u001b[33mbs4\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mhtml5lib\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m915\u001b[39m     \u001b[43mimport_optional_dependency\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhtml5lib\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    916\u001b[39m     import_optional_dependency(\u001b[33m\"\u001b[39m\u001b[33mbs4\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    917\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Data Science Project\\.venv\\Lib\\site-packages\\pandas\\compat\\_optional.py:138\u001b[39m, in \u001b[36mimport_optional_dependency\u001b[39m\u001b[34m(name, extra, errors, min_version)\u001b[39m\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[32m    137\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m errors == \u001b[33m\"\u001b[39m\u001b[33mraise\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m138\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[32m    139\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    141\u001b[39m \u001b[38;5;66;03m# Handle submodules: if we have submodule, grab parent module from sys.modules\u001b[39;00m\n",
      "\u001b[31mImportError\u001b[39m: Missing optional dependency 'html5lib'.  Use pip or conda to install html5lib."
     ]
    }
   ],
   "source": [
    "pd.read_html(str(tables[5]), flavor='bs4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29cbdb1f-ea3c-496b-a898-15652bf47efe",
   "metadata": {},
   "source": [
    "The function `read_html` always returns a list of DataFrames so we must pick the one we want out of the list.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "70cc3cc4-e8ea-409a-acb7-cebb63b826ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\epics\\AppData\\Local\\Temp\\ipykernel_20240\\3554864673.py:1: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  population_data_read_html = pd.read_html(str(tables[5]), flavor='bs4')[0]\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Missing optional dependency 'html5lib'.  Use pip or conda to install html5lib.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Data Science Project\\.venv\\Lib\\site-packages\\pandas\\compat\\_optional.py:135\u001b[39m, in \u001b[36mimport_optional_dependency\u001b[39m\u001b[34m(name, extra, errors, min_version)\u001b[39m\n\u001b[32m    134\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m135\u001b[39m     module = \u001b[43mimportlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Python314\\Lib\\importlib\\__init__.py:88\u001b[39m, in \u001b[36mimport_module\u001b[39m\u001b[34m(name, package)\u001b[39m\n\u001b[32m     87\u001b[39m         level += \u001b[32m1\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1398\u001b[39m, in \u001b[36m_gcd_import\u001b[39m\u001b[34m(name, package, level)\u001b[39m\n\u001b[32m   1397\u001b[39m     name = _resolve_name(name, package, level)\n\u001b[32m-> \u001b[39m\u001b[32m1398\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_find_and_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_gcd_import\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1371\u001b[39m, in \u001b[36m_find_and_load\u001b[39m\u001b[34m(name, import_)\u001b[39m\n\u001b[32m   1370\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m module \u001b[38;5;129;01mis\u001b[39;00m _NEEDS_LOADING:\n\u001b[32m-> \u001b[39m\u001b[32m1371\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_find_and_load_unlocked\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimport_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1373\u001b[39m \u001b[38;5;66;03m# Optimization: only call _bootstrap._lock_unlock_module() if\u001b[39;00m\n\u001b[32m   1374\u001b[39m \u001b[38;5;66;03m# module.__spec__._initializing is True.\u001b[39;00m\n\u001b[32m   1375\u001b[39m \u001b[38;5;66;03m# NOTE: because of this, initializing must be set *before*\u001b[39;00m\n\u001b[32m   1376\u001b[39m \u001b[38;5;66;03m# putting the new module in sys.modules.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1335\u001b[39m, in \u001b[36m_find_and_load_unlocked\u001b[39m\u001b[34m(name, import_)\u001b[39m\n\u001b[32m   1334\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m spec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1335\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_ERR_MSG_PREFIX\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m'\u001b[39m, name=name)\n\u001b[32m   1336\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'html5lib'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[80]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m population_data_read_html = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_html\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtables\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflavor\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mbs4\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m]\n\u001b[32m      3\u001b[39m population_data_read_html\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Data Science Project\\.venv\\Lib\\site-packages\\pandas\\io\\html.py:1240\u001b[39m, in \u001b[36mread_html\u001b[39m\u001b[34m(io, match, flavor, header, index_col, skiprows, attrs, parse_dates, thousands, encoding, decimal, converters, na_values, keep_default_na, displayed_only, extract_links, dtype_backend, storage_options)\u001b[39m\n\u001b[32m   1224\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[32m   1225\u001b[39m     [\n\u001b[32m   1226\u001b[39m         is_file_like(io),\n\u001b[32m   (...)\u001b[39m\u001b[32m   1230\u001b[39m     ]\n\u001b[32m   1231\u001b[39m ):\n\u001b[32m   1232\u001b[39m     warnings.warn(\n\u001b[32m   1233\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPassing literal html to \u001b[39m\u001b[33m'\u001b[39m\u001b[33mread_html\u001b[39m\u001b[33m'\u001b[39m\u001b[33m is deprecated and \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1234\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mwill be removed in a future version. To read from a \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1237\u001b[39m         stacklevel=find_stack_level(),\n\u001b[32m   1238\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1240\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_parse\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1241\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflavor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mflavor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1242\u001b[39m \u001b[43m    \u001b[49m\u001b[43mio\u001b[49m\u001b[43m=\u001b[49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1243\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmatch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1244\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1245\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1246\u001b[39m \u001b[43m    \u001b[49m\u001b[43mskiprows\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskiprows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1247\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1248\u001b[39m \u001b[43m    \u001b[49m\u001b[43mthousands\u001b[49m\u001b[43m=\u001b[49m\u001b[43mthousands\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1249\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1250\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1251\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecimal\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecimal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1252\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconverters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconverters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1253\u001b[39m \u001b[43m    \u001b[49m\u001b[43mna_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mna_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1254\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkeep_default_na\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeep_default_na\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1255\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdisplayed_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdisplayed_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1256\u001b[39m \u001b[43m    \u001b[49m\u001b[43mextract_links\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextract_links\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1257\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1258\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1259\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Data Science Project\\.venv\\Lib\\site-packages\\pandas\\io\\html.py:971\u001b[39m, in \u001b[36m_parse\u001b[39m\u001b[34m(flavor, io, match, attrs, encoding, displayed_only, extract_links, storage_options, **kwargs)\u001b[39m\n\u001b[32m    969\u001b[39m retained = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    970\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m flav \u001b[38;5;129;01min\u001b[39;00m flavor:\n\u001b[32m--> \u001b[39m\u001b[32m971\u001b[39m     parser = \u001b[43m_parser_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mflav\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    972\u001b[39m     p = parser(\n\u001b[32m    973\u001b[39m         io,\n\u001b[32m    974\u001b[39m         compiled_match,\n\u001b[32m   (...)\u001b[39m\u001b[32m    979\u001b[39m         storage_options,\n\u001b[32m    980\u001b[39m     )\n\u001b[32m    982\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Data Science Project\\.venv\\Lib\\site-packages\\pandas\\io\\html.py:915\u001b[39m, in \u001b[36m_parser_dispatch\u001b[39m\u001b[34m(flavor)\u001b[39m\n\u001b[32m    910\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    911\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(flavor)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m is not a valid flavor, valid flavors are \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalid_parsers\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    912\u001b[39m     )\n\u001b[32m    914\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m flavor \u001b[38;5;129;01min\u001b[39;00m (\u001b[33m\"\u001b[39m\u001b[33mbs4\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mhtml5lib\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m915\u001b[39m     \u001b[43mimport_optional_dependency\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhtml5lib\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    916\u001b[39m     import_optional_dependency(\u001b[33m\"\u001b[39m\u001b[33mbs4\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    917\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Data Science Project\\.venv\\Lib\\site-packages\\pandas\\compat\\_optional.py:138\u001b[39m, in \u001b[36mimport_optional_dependency\u001b[39m\u001b[34m(name, extra, errors, min_version)\u001b[39m\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[32m    137\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m errors == \u001b[33m\"\u001b[39m\u001b[33mraise\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m138\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[32m    139\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    141\u001b[39m \u001b[38;5;66;03m# Handle submodules: if we have submodule, grab parent module from sys.modules\u001b[39;00m\n",
      "\u001b[31mImportError\u001b[39m: Missing optional dependency 'html5lib'.  Use pip or conda to install html5lib."
     ]
    }
   ],
   "source": [
    "population_data_read_html = pd.read_html(str(tables[5]), flavor='bs4')[0]\n",
    "\n",
    "population_data_read_html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52582a10-d7a5-46a1-8211-55fd4898d7d6",
   "metadata": {},
   "source": [
    "## Scrape data from HTML tables into a DataFrame using read_html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b63245d-c1e1-49c3-9eb5-1d267ec2defd",
   "metadata": {},
   "source": [
    "We can also use the `read_html` function to directly get DataFrames from a `webpage`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "519daa78-12c8-4733-a88b-be9d0e929c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\epics\\AppData\\Local\\Temp\\ipykernel_20240\\1236615591.py:1: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dataframe_list = pd.read_html(data.text, flavor='bs4')\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Missing optional dependency 'html5lib'.  Use pip or conda to install html5lib.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Data Science Project\\.venv\\Lib\\site-packages\\pandas\\compat\\_optional.py:135\u001b[39m, in \u001b[36mimport_optional_dependency\u001b[39m\u001b[34m(name, extra, errors, min_version)\u001b[39m\n\u001b[32m    134\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m135\u001b[39m     module = \u001b[43mimportlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Python314\\Lib\\importlib\\__init__.py:88\u001b[39m, in \u001b[36mimport_module\u001b[39m\u001b[34m(name, package)\u001b[39m\n\u001b[32m     87\u001b[39m         level += \u001b[32m1\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1398\u001b[39m, in \u001b[36m_gcd_import\u001b[39m\u001b[34m(name, package, level)\u001b[39m\n\u001b[32m   1397\u001b[39m     name = _resolve_name(name, package, level)\n\u001b[32m-> \u001b[39m\u001b[32m1398\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_find_and_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_gcd_import\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1371\u001b[39m, in \u001b[36m_find_and_load\u001b[39m\u001b[34m(name, import_)\u001b[39m\n\u001b[32m   1370\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m module \u001b[38;5;129;01mis\u001b[39;00m _NEEDS_LOADING:\n\u001b[32m-> \u001b[39m\u001b[32m1371\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_find_and_load_unlocked\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimport_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1373\u001b[39m \u001b[38;5;66;03m# Optimization: only call _bootstrap._lock_unlock_module() if\u001b[39;00m\n\u001b[32m   1374\u001b[39m \u001b[38;5;66;03m# module.__spec__._initializing is True.\u001b[39;00m\n\u001b[32m   1375\u001b[39m \u001b[38;5;66;03m# NOTE: because of this, initializing must be set *before*\u001b[39;00m\n\u001b[32m   1376\u001b[39m \u001b[38;5;66;03m# putting the new module in sys.modules.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1335\u001b[39m, in \u001b[36m_find_and_load_unlocked\u001b[39m\u001b[34m(name, import_)\u001b[39m\n\u001b[32m   1334\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m spec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1335\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_ERR_MSG_PREFIX\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m'\u001b[39m, name=name)\n\u001b[32m   1336\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'html5lib'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[81]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m dataframe_list = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_html\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflavor\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mbs4\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Data Science Project\\.venv\\Lib\\site-packages\\pandas\\io\\html.py:1240\u001b[39m, in \u001b[36mread_html\u001b[39m\u001b[34m(io, match, flavor, header, index_col, skiprows, attrs, parse_dates, thousands, encoding, decimal, converters, na_values, keep_default_na, displayed_only, extract_links, dtype_backend, storage_options)\u001b[39m\n\u001b[32m   1224\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[32m   1225\u001b[39m     [\n\u001b[32m   1226\u001b[39m         is_file_like(io),\n\u001b[32m   (...)\u001b[39m\u001b[32m   1230\u001b[39m     ]\n\u001b[32m   1231\u001b[39m ):\n\u001b[32m   1232\u001b[39m     warnings.warn(\n\u001b[32m   1233\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPassing literal html to \u001b[39m\u001b[33m'\u001b[39m\u001b[33mread_html\u001b[39m\u001b[33m'\u001b[39m\u001b[33m is deprecated and \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1234\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mwill be removed in a future version. To read from a \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1237\u001b[39m         stacklevel=find_stack_level(),\n\u001b[32m   1238\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1240\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_parse\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1241\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflavor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mflavor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1242\u001b[39m \u001b[43m    \u001b[49m\u001b[43mio\u001b[49m\u001b[43m=\u001b[49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1243\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmatch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1244\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1245\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1246\u001b[39m \u001b[43m    \u001b[49m\u001b[43mskiprows\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskiprows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1247\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1248\u001b[39m \u001b[43m    \u001b[49m\u001b[43mthousands\u001b[49m\u001b[43m=\u001b[49m\u001b[43mthousands\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1249\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1250\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1251\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecimal\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecimal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1252\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconverters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconverters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1253\u001b[39m \u001b[43m    \u001b[49m\u001b[43mna_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mna_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1254\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkeep_default_na\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeep_default_na\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1255\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdisplayed_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdisplayed_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1256\u001b[39m \u001b[43m    \u001b[49m\u001b[43mextract_links\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextract_links\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1257\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1258\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1259\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Data Science Project\\.venv\\Lib\\site-packages\\pandas\\io\\html.py:971\u001b[39m, in \u001b[36m_parse\u001b[39m\u001b[34m(flavor, io, match, attrs, encoding, displayed_only, extract_links, storage_options, **kwargs)\u001b[39m\n\u001b[32m    969\u001b[39m retained = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    970\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m flav \u001b[38;5;129;01min\u001b[39;00m flavor:\n\u001b[32m--> \u001b[39m\u001b[32m971\u001b[39m     parser = \u001b[43m_parser_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mflav\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    972\u001b[39m     p = parser(\n\u001b[32m    973\u001b[39m         io,\n\u001b[32m    974\u001b[39m         compiled_match,\n\u001b[32m   (...)\u001b[39m\u001b[32m    979\u001b[39m         storage_options,\n\u001b[32m    980\u001b[39m     )\n\u001b[32m    982\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Data Science Project\\.venv\\Lib\\site-packages\\pandas\\io\\html.py:915\u001b[39m, in \u001b[36m_parser_dispatch\u001b[39m\u001b[34m(flavor)\u001b[39m\n\u001b[32m    910\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    911\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(flavor)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m is not a valid flavor, valid flavors are \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalid_parsers\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    912\u001b[39m     )\n\u001b[32m    914\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m flavor \u001b[38;5;129;01min\u001b[39;00m (\u001b[33m\"\u001b[39m\u001b[33mbs4\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mhtml5lib\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m915\u001b[39m     \u001b[43mimport_optional_dependency\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhtml5lib\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    916\u001b[39m     import_optional_dependency(\u001b[33m\"\u001b[39m\u001b[33mbs4\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    917\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Data Science Project\\.venv\\Lib\\site-packages\\pandas\\compat\\_optional.py:138\u001b[39m, in \u001b[36mimport_optional_dependency\u001b[39m\u001b[34m(name, extra, errors, min_version)\u001b[39m\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[32m    137\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m errors == \u001b[33m\"\u001b[39m\u001b[33mraise\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m138\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[32m    139\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    141\u001b[39m \u001b[38;5;66;03m# Handle submodules: if we have submodule, grab parent module from sys.modules\u001b[39;00m\n",
      "\u001b[31mImportError\u001b[39m: Missing optional dependency 'html5lib'.  Use pip or conda to install html5lib."
     ]
    }
   ],
   "source": [
    "dataframe_list = pd.read_html(data.text, flavor='bs4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce24cc5-27d2-4527-a1be-7328e65dc876",
   "metadata": {},
   "source": [
    "We can see there are 26 DataFrames just like when we used `find_all` on the `soup` object.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ff34485d-6ba3-440a-99e4-5c1b0fe720c8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataframe_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[82]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[43mdataframe_list\u001b[49m)\n",
      "\u001b[31mNameError\u001b[39m: name 'dataframe_list' is not defined"
     ]
    }
   ],
   "source": [
    "len(dataframe_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c7588d-7233-48cd-afc6-fb22c8fa601b",
   "metadata": {},
   "source": [
    "Finally we can pick the DataFrame we need out of the list.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2324a3ae-7e67-43cb-9ca8-0b8facb4328b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataframe_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[83]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mdataframe_list\u001b[49m[\u001b[32m5\u001b[39m]\n",
      "\u001b[31mNameError\u001b[39m: name 'dataframe_list' is not defined"
     ]
    }
   ],
   "source": [
    "dataframe_list[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec194e9b-1fdb-4291-b3aa-2b8b6a606df5",
   "metadata": {},
   "source": [
    "We can also use the `match` parameter to select the specific table we want. If the table contains a string matching the text it will be read.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "52aad111-69e1-42e5-a669-41433dccce87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Rank                 Country  Population  Area (km2)  Density (pop/km2)\n",
      "0     1               Singapore     5921231         719               8235\n",
      "1     2              Bangladesh   165650475      148460               1116\n",
      "2     3  Palestine[note 3][102]     5223000        6025                867\n",
      "3     4          Taiwan[note 4]    23580712       35980                655\n",
      "4     5             South Korea    51844834       99720                520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\epics\\AppData\\Local\\Temp\\ipykernel_20240\\4268838743.py:7: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_html(str(table))[0]\n"
     ]
    }
   ],
   "source": [
    "heading = soup.find(\"h3\", {\"id\": \"Most_densely_populated_countries\"})\n",
    "\n",
    "# Get the next table after this heading\n",
    "table = heading.find_next(\"table\")\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.read_html(str(table))[0]\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd64b8b-28ca-4a61-a464-98cbe234c8a2",
   "metadata": {},
   "source": [
    "## Authors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc87239f-d390-4e61-9584-8f43b7973a1b",
   "metadata": {},
   "source": [
    "Ramesh Sannareddy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519b794f-6b16-4640-88a6-9df7ad2e7fda",
   "metadata": {},
   "source": [
    "### Other Contributors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95848957-4bac-474c-8d17-1ebdf4c0e69a",
   "metadata": {},
   "source": [
    "Rav Ahuja\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a317d8b-9eef-4272-aa53-af403a135fee",
   "metadata": {},
   "source": [
    "<!-- ## Change Log\n",
    "| Date (YYYY-MM-DD) | Version | Changed By                                               | Change Description |\n",
    "| ----------------- | ------- | -------------------------------------------------------- | ------------------ |\n",
    "| 2021-08-04        | 0.2     | Made changes to markdown of nextsibling                  |                    |\n",
    "| 2020-10-17        | 0.1     | Joseph Santarcangelo  Created initial version of the lab |                    |\n",
    "--!>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c82922c-5c57-4446-97fd-cce46002d579",
   "metadata": {},
   "source": [
    "####  Copyright © 2020 IBM Corporation. This notebook and its source code are released under the terms of the [MIT License](https://cognitiveclass.ai/mit-license?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkPY0220ENSkillsNetwork23455606-2021-01-01&cm_mmc=Email_Newsletter-\\_-Developer_Ed%2BTech-\\_-WW_WW-\\_-SkillsNetwork-Courses-IBMDeveloperSkillsNetwork-PY0101EN-SkillsNetwork-19487395&cm_mmca1=000026UJ&cm_mmca2=10006555&cm_mmca3=M12345678&cvosrc=email.Newsletter.M12345678&cvo_campaign=000026UJ).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.14.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  },
  "prev_pub_hash": "624707a4d029edb905f23f1bce193f52eeb0bd4ae865f5ea6b1d552726e0c7c8"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
